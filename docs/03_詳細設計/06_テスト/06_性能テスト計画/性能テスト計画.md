# SES業務システム 性能テスト計画

## 1. はじめに

### 1.1 目的

本ドキュメントは、SES業務システムの性能テストに関する詳細な計画を定義する。システムの応答性、安定性、スケーラビリティなどの非機能要件を検証するためのアプローチ、方法、および基準を提供する。性能テストによって、本番環境での実際の使用状況下でのシステムの動作を予測し、パフォーマンスに関する問題を早期に発見・解決することを目指す。

### 1.2 適用範囲

本性能テスト計画は、SES業務システムの以下の性能特性を検証する：

- 応答時間（レスポンスタイム）
- スループット（処理能力）
- リソース使用率（CPU、メモリ、ディスク、ネットワーク）
- スケーラビリティ（負荷増加時の挙動）
- 安定性（長時間運用時の挙動）
- 同時ユーザー数の処理能力
- ボトルネックの特定
- データベースパフォーマンス
- キャッシュ効果

### 1.3 参照ドキュメント

- [テスト方針概要](/docs/03_詳細設計/06_テスト/01_テスト方針/テスト方針概要.md)
- [非機能要件定義](/docs/01_要件定義/要件定義書.html)
- [システム設計書：性能設計](/docs/02_基本設計/システム設計/06_性能設計.html)
- [詳細設計：アーキテクチャ概要](/docs/03_詳細設計/01_アーキテクチャ/アーキテクチャ概要.md)
- [DB設計：インデックス設計](/docs/03_詳細設計/03_DB/05_インデックス設計.md)

## 2. 性能テスト戦略

### 2.1 性能テストの種類

SES業務システムの性能検証のために、以下のタイプのテストを実施する：

#### 2.1.1 負荷テスト（Load Testing）

通常の予想負荷および最大予想負荷の条件下でのシステム動作を検証する。

- **目的**: 予想される通常使用時と最大使用時のシステム応答性を検証
- **アプローチ**: 現実的なユーザー数とシナリオでの段階的な負荷増加
- **指標**: 応答時間、スループット、エラー率、リソース使用率

#### 2.1.2 ストレステスト（Stress Testing）

システムの限界を検証し、過負荷状態での挙動を確認する。

- **目的**: システムの破綻点（ブレイクポイント）を特定
- **アプローチ**: 想定最大負荷を超える条件での段階的な負荷増加
- **指標**: 最大同時ユーザー数、最大スループット、障害モード

#### 2.1.3 耐久テスト（Endurance Testing）

長時間の連続使用下でのシステム安定性を検証する。

- **目的**: メモリリーク、リソース枯渇、パフォーマンス低下などの経時的問題を検出
- **アプローチ**: 通常負荷での長時間（12-24時間）の連続運用
- **指標**: 応答時間の一貫性、メモリ使用の推移、エラー率の変化

#### 2.1.4 スパイクテスト（Spike Testing）

急激な負荷増加に対するシステムの反応を検証する。

- **目的**: 突発的なユーザー増加への対応能力を評価
- **アプローチ**: 短時間での急激な負荷増加と減少
- **指標**: 負荷急増時の応答性、リカバリー時間、エラー発生状況

#### 2.1.5 スケーラビリティテスト（Scalability Testing）

リソース追加時のシステム性能の向上度合いを検証する。

- **目的**: システムのスケールアウト/スケールアップ特性を把握
- **アプローチ**: 段階的なリソース増加と負荷テストの組み合わせ
- **指標**: リソース増加に対する性能向上率

#### 2.1.6 ボリュームテスト（Volume Testing）

大量データ処理時のシステム挙動を検証する。

- **目的**: 大量データ環境での処理能力を確認
- **アプローチ**: 大規模なデータセットでの操作実行
- **指標**: データ量増加に対する応答時間変化、処理時間、リソース消費

### 2.2 テスト対象コンポーネント

性能テストの重点対象となる主要コンポーネント：

| コンポーネント | 重要度 | 理由 |
|-------------|-------|------|
| マッチングエンジン | 高 | 複雑な計算処理を含み、ボトルネックになる可能性が高い |
| 契約管理・電子署名 | 高 | ビジネス上重要なトランザクションで高い応答性が必要 |
| 検索機能 | 高 | 頻繁に使用され、大量データに対する処理が必要 |
| 請求書生成 | 高 | 大量データ処理と計算を含む重要バッチ処理 |
| レポート生成 | 高 | 複雑な集計処理と大量データ処理を含む |
| 勤怠データ一括処理 | 中 | 月次など特定のタイミングで大量データを処理 |
| ファイルアップロード/ダウンロード | 中 | 大容量ファイル転送が発生する可能性がある |
| ダッシュボード表示 | 中 | リアルタイム性が要求される複合データ表示 |
| ユーザー認証 | 中 | 同時アクセス時の認証処理負荷の確認が必要 |
| システム管理機能 | 低 | 使用頻度が低く、性能クリティカルではない |

### 2.3 性能要件と目標値

要件定義書およびシステム設計書から導出した性能目標：

#### 2.3.1 全体性能要件

| 要件 | 説明 | 目標値 |
|-----|------|-------|
| 同時ユーザー数 | 同時アクセスユーザー数 | 500ユーザー |
| 平均応答時間 | 全トランザクションの平均 | 2秒以内 |
| ピーク時応答時間 | 負荷ピーク時の平均応答時間 | 3秒以内 |
| 最大応答時間 | 95パーセンタイル | 5秒以内 |
| スループット | 1時間あたりの最大トランザクション数 | 10,000トランザクション/時間 |
| CPU使用率 | 通常負荷時の平均CPU使用率 | 60%以下 |
| メモリ使用率 | 通常負荷時の平均メモリ使用率 | 70%以下 |
| データベース接続数 | 最大同時接続数 | 100 |
| 障害復旧時間 | 障害発生から復旧までの時間 | 10分以内 |

#### 2.3.2 機能別性能要件

| 機能 | 応答時間要件 | スループット要件 | ユーザー数 |
|-----|------------|----------------|---------|
| ログイン | 1秒以内 | 50トランザクション/秒 | 100同時ユーザー |
| 技術者検索 | 3秒以内 | 30トランザクション/秒 | 50同時ユーザー |
| 案件検索 | 3秒以内 | 30トランザクション/秒 | 50同時ユーザー |
| マッチング検索 | 5秒以内 | 20トランザクション/秒 | 30同時ユーザー |
| 契約書生成 | 10秒以内 | 5トランザクション/秒 | 20同時ユーザー |
| 請求書生成 | 15秒以内 | 5トランザクション/秒 | 15同時ユーザー |
| レポート表示 | 5秒以内 | 10トランザクション/秒 | 30同時ユーザー |
| ダッシュボード表示 | 3秒以内 | 20トランザクション/秒 | 50同時ユーザー |

#### 2.3.3 バッチ処理性能要件

| バッチ処理 | 最大実行時間 | データ量 | 実行頻度 |
|----------|------------|---------|---------|
| 月次請求処理 | 30分以内 | 10,000レコード | 月1回 |
| 日次集計処理 | 15分以内 | 5,000レコード | 日1回 |
| レポートデータ集計 | 20分以内 | 全データ | 日1回 |
| マスタデータ更新 | 10分以内 | 1,000レコード | 週1回 |
| バックアップ処理 | 60分以内 | 全データ | 日1回 |

## 3. テスト環境

### 3.1 テスト環境構成

#### 3.1.1 性能テスト専用環境

| コンポーネント | 仕様 |
|-------------|------|
| アプリケーションサーバー | 8 vCPU, 32GB RAM, SSD 100GB x 2台 |
| データベースサーバー | 16 vCPU, 64GB RAM, SSD 500GB (RAID10) |
| ロードバランサー | AWS Application Load Balancer |
| ファイルストレージ | AWS S3互換ストレージ 1TB |
| キャッシュサーバー | Redis 6.x, 16GB RAM |
| 監視サーバー | 4 vCPU, 16GB RAM, SSD 100GB |
| 負荷生成サーバー | 8 vCPU, 32GB RAM, SSD 100GB x 2台 |

#### 3.1.2 環境ネットワーク構成

```
[負荷生成サーバー] -+
                     |
                     +-> [ロードバランサー] -> [アプリケーションサーバー クラスタ] -> [データベースサーバー]
                     |                                |
[監視サーバー] ------+                                v
                                                 [キャッシュサーバー]
                                                      |
                                                      v
                                               [ファイルストレージ]
```

#### 3.1.3 テストデータ

テストに使用するデータの規模と特性：

| データ種別 | 量 | 特性 |
|----------|------|------|
| ユーザーアカウント | 1,000件 | 管理者、営業、事務等の役割分布 |
| 技術者プロフィール | 10,000件 | 様々なスキルセット、経験年数の分布 |
| 案件データ | 5,000件 | 様々なスキル要件、期間、単価の分布 |
| 契約データ | 3,000件 | 様々な契約形態、期間の分布 |
| 勤怠データ | 100,000件 | 6か月分の日次データ |
| 請求データ | 10,000件 | 12か月分の月次データ |
| 添付ファイル | 20,000件 | 様々なサイズ(10KB〜10MB)の分布 |

#### 3.1.4 テスト環境と本番環境の差異

| 項目 | テスト環境 | 本番環境 | 影響と調整方法 |
|-----|----------|----------|--------------|
| サーバー性能 | やや低スペック | 高スペック | 結果を割り増して評価 |
| データ量 | 実データの約30% | 100% | データ量の影響を考慮した推定 |
| ネットワーク | 同一リージョン内 | 複数リージョン展開 | ネットワーク遅延をシミュレート |
| 外部連携 | モック | 実連携 | 外部サービスの影響は別途評価 |
| セキュリティ | 一部機能無効化 | 全機能有効 | セキュリティによる影響を考慮 |

### 3.2 テストツールとモニタリング

#### 3.2.1 性能テストツール

| ツール | 用途 | バージョン |
|-------|------|----------|
| JMeter | 負荷テスト、API性能テスト | 5.5.x |
| Gatling | 高負荷シナリオテスト | 3.9.x |
| Locust | リアルユーザーシミュレーション | 2.15.x |
| K6 | スクリプトベースの負荷テスト | 0.44.x |
| Apache Bench | 単純なHTTPベンチマーク | 最新版 |
| Selenium Grid | ブラウザベース性能テスト | 4.8.x |

#### 3.2.2 モニタリングツール

| ツール | 監視対象 | 収集指標 |
|-------|---------|---------|
| Prometheus | アプリケーション、サーバー | CPU、メモリ、スレッド、GC、カスタムメトリクス |
| Grafana | 可視化 | ダッシュボード、アラート、時系列データ可視化 |
| Elasticsearch + Kibana | ログ分析 | エラーログ、アクセスログ、アプリケーションログ |
| MySQL Exporter | データベース | クエリ実行時間、接続数、キャッシュヒット率 |
| cAdvisor | コンテナ | コンテナリソース使用率 |
| Node Exporter | ホスト | OS・ハードウェアメトリクス |

#### 3.2.3 収集メトリクス

以下のメトリクスを継続的に収集し分析する：

1. **システムレベルメトリクス**
   - CPU使用率 (ユーザー/システム/IO待ち)
   - メモリ使用率 (実メモリ、スワップ)
   - ディスクI/O (読み書きスループット、レイテンシ)
   - ネットワークI/O (受信/送信スループット、パケット損失)
   - ファイルシステム使用率

2. **アプリケーションレベルメトリクス**
   - JVMヒープ使用量
   - GC頻度と時間
   - スレッドプール使用状況
   - 処理中リクエスト数
   - キャッシュヒット率
   - エラー率

3. **データベースメトリクス**
   - クエリ実行時間
   - スロークエリ発生数
   - インデックス使用率
   - テーブルスキャン数
   - 接続プール状態
   - トランザクション数

4. **ユーザー体験メトリクス**
   - ページロード時間
   - API応答時間
   - ファーストバイトタイム
   - コンポーネントレンダリング時間
   - クライアントエラー数

## 4. テストシナリオと実行計画

### 4.1 主要ビジネスシナリオ

実際のユーザー行動を模した主要なビジネスシナリオ：

#### 4.1.1 技術者管理シナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-01 | 技術者一括登録 | 100件の技術者データをCSVで一括登録し、処理時間を測定 | 高 |
| PS-02 | 技術者検索 | 複数の検索条件を組み合わせた技術者検索の応答時間測定 | 高 |
| PS-03 | 技術者プロフィール閲覧 | 技術者詳細情報表示の応答時間測定 | 中 |
| PS-04 | スキルシート生成 | 技術者のスキルシートPDF生成時間の測定 | 中 |

#### 4.1.2 案件管理シナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-05 | 案件一括登録 | 50件の案件データを一括登録し、処理時間を測定 | 高 |
| PS-06 | 案件検索 | 複数の検索条件を組み合わせた案件検索の応答時間測定 | 高 |
| PS-07 | 案件詳細閲覧 | 案件詳細情報表示の応答時間測定 | 中 |

#### 4.1.3 マッチングシナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-08 | マッチング検索 | 1案件に対する技術者マッチング検索の応答時間測定 | 高 |
| PS-09 | 逆マッチング検索 | 1技術者に対する案件マッチング検索の応答時間測定 | 高 |
| PS-10 | 一括マッチング処理 | 100件の案件に対する一括マッチング処理時間測定 | 中 |

#### 4.1.4 契約管理シナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-11 | 契約書生成 | 契約情報からの契約書PDF生成時間測定 | 高 |
| PS-12 | 電子署名処理 | 電子署名フローの処理時間測定 | 高 |
| PS-13 | 契約一覧表示 | 500件の契約から条件検索した一覧表示の応答時間測定 | 中 |

#### 4.1.5 勤怠管理シナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-14 | 勤怠一括登録 | 1,000人分の月次勤怠データ一括登録処理時間測定 | 高 |
| PS-15 | 勤怠承認処理 | 100件の勤怠データ連続承認処理の時間測定 | 高 |
| PS-16 | 勤怠集計処理 | 3,000人×6か月分の勤怠データ集計処理時間測定 | 高 |

#### 4.1.6 請求支払管理シナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-17 | 請求書一括生成 | 500件の請求書を一括生成する処理時間測定 | 高 |
| PS-18 | 請求明細PDF生成 | 複雑な内訳を含む請求書PDF生成時間測定 | 高 |
| PS-19 | 請求データエクスポート | 3年分の請求データCSVエクスポート処理時間測定 | 中 |

#### 4.1.7 レポートシナリオ

| ID | シナリオ | 詳細 | 優先度 |
|----|---------|------|-------|
| PS-20 | KPIダッシュボード表示 | 全社KPIダッシュボード初期表示の応答時間測定 | 高 |
| PS-21 | 売上レポート生成 | 年次・月次売上レポート生成の処理時間測定 | 高 |
| PS-22 | カスタムレポート生成 | 複雑な条件指定によるカスタムレポート生成時間測定 | 中 |

### 4.2 複合負荷シナリオ

実際の業務中に複数ユーザーが同時に操作する状況を模したシナリオ：

#### 4.2.1 平常業務シナリオ

| ID | シナリオ | 詳細 | ユーザー構成 |
|----|---------|------|------------|
| CS-01 | 平常業務オペレーション | 日常的な業務操作の組み合わせでの負荷テスト | 営業50名<br>事務30名<br>管理者5名<br>技術者100名 |

**具体的な操作組み合わせ：**

- 営業担当者：案件登録/更新、技術者検索、マッチング検索、契約書生成
- 事務担当者：勤怠データ登録/確認、請求書生成、支払い登録
- 管理者：各種承認作業、レポート閲覧
- 技術者：勤怠入力、スキル更新、案件閲覧

#### 4.2.2 月末業務シナリオ

| ID | シナリオ | 詳細 | ユーザー構成 |
|----|---------|------|------------|
| CS-02 | 月末業務集中 | 月末特有の集中作業を模した負荷テスト | 営業80名<br>事務50名<br>管理者10名<br>技術者300名 |

**具体的な操作組み合わせ：**

- 営業担当者：案件更新、次月予測入力、契約更新確認
- 事務担当者：月次締め処理、請求書一括生成、請求書発行
- 管理者：月次レポート生成、KPI確認、承認作業
- 技術者：月次勤怠確定、経費精算、勤務予定入力

#### 4.2.3 一斉アクセスシナリオ

| ID | シナリオ | 詳細 | ユーザー構成 |
|----|---------|------|------------|
| CS-03 | 朝の一斉ログイン | 始業時の一斉ログインと初期操作を模した負荷テスト | 全ユーザー500名が<br>10分間に集中ログイン |

**具体的な操作組み合わせ：**

- ログイン処理
- ダッシュボード表示
- 未読通知確認
- 当日タスク確認
- 勤怠入力

### 4.3 テスト実行計画

#### 4.3.1 負荷テスト実行計画

| テストID | 概要 | ユーザー数 | 継続時間 | 実施タイミング |
|---------|------|----------|---------|------------|
| LT-01 | 段階的負荷テスト | 50→100→200→300→500 | 各段階15分 | 毎スプリント |
| LT-02 | 平常負荷テスト | 200 | 2時間 | 隔週 |
| LT-03 | 最大負荷テスト | 500 | 1時間 | 月1回 |
| LT-04 | ビジネスシナリオテスト | シナリオ別 | シナリオ別 | スプリント終了時 |

#### 4.3.2 ストレステスト実行計画

| テストID | 概要 | ユーザー数 | 継続時間 | 実施タイミング |
|---------|------|----------|---------|------------|
| ST-01 | ブレイクポイント特定 | 500→1000→増加継続 | 段階的に1時間 | 月1回 |
| ST-02 | 回復性テスト | 最大負荷→通常負荷 | 最大30分→回復30分 | 月1回 |
| ST-03 | リソース制限テスト | 200 | 1時間 | 特定機能変更時 |

#### 4.3.3 耐久テスト実行計画

| テストID | 概要 | ユーザー数 | 継続時間 | 実施タイミング |
|---------|------|----------|---------|------------|
| ET-01 | 標準耐久テスト | 200 | 12時間 | 2週に1回 |
| ET-02 | 長期耐久テスト | 150 | 24時間 | 月1回 |
| ET-03 | 変動負荷耐久テスト | 100〜300 | 8時間 | 主要リリース前 |

#### 4.3.4 スパイクテスト実行計画

| テストID | 概要 | ユーザー数 | 継続時間 | 実施タイミング |
|---------|------|----------|---------|------------|
| SPT-01 | 急激負荷増加テスト | 50→500 | 10分 | 月1回 |
| SPT-02 | 繰り返しスパイクテスト | 100→400→100 | 各スパイク15分×3回 | 主要リリース前 |

#### 4.3.5 ボリュームテスト実行計画

| テストID | 概要 | データ量 | 実施タイミング |
|---------|------|---------|------------|
| VT-01 | 大量データ検索テスト | 10万件 | 機能変更時 |
| VT-02 | 大量ファイル処理テスト | 1万ファイル | 機能変更時 |
| VT-03 | 長期データレポートテスト | 5年分 | 四半期に1回 |

### 4.4 JMeter実行スクリプト例

#### 4.4.1 基本負荷テストスクリプト構造

```xml
<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2" properties="5.0" jmeter="5.5">
  <hashTree>
    <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="SES業務システム負荷テスト" enabled="true">
      <stringProp name="TestPlan.comments">SES業務システムの基本性能検証</stringProp>
      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
      
      <!-- グローバル変数 -->
      <elementProp name="TestPlan.user_defined_variables" elementType="Arguments">
        <collectionProp name="Arguments.arguments">
          <elementProp name="HOST" elementType="Argument">
            <stringProp name="Argument.name">HOST</stringProp>
            <stringProp name="Argument.value">test-perf.ses-system.example.com</stringProp>
          </elementProp>
          <elementProp name="PORT" elementType="Argument">
            <stringProp name="Argument.name">PORT</stringProp>
            <stringProp name="Argument.value">443</stringProp>
          </elementProp>
          <elementProp name="PROTOCOL" elementType="Argument">
            <stringProp name="Argument.name">PROTOCOL</stringProp>
            <stringProp name="Argument.value">https</stringProp>
          </elementProp>
        </collectionProp>
      </elementProp>
      
      <!-- テストスレッドグループ -->
      <hashTree>
        <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="営業担当者シナリオ" enabled="true">
          <stringProp name="ThreadGroup.num_threads">50</stringProp>
          <stringProp name="ThreadGroup.ramp_time">60</stringProp>
          <boolProp name="ThreadGroup.scheduler">true</boolProp>
          <stringProp name="ThreadGroup.duration">1800</stringProp>
          <stringProp name="ThreadGroup.delay">0</stringProp>
          
          <!-- テストユーザーデータ -->
          <CSVDataSet guiclass="TestBeanGUI" testclass="CSVDataSet" testname="ユーザーデータ" enabled="true">
            <stringProp name="filename">sales_users.csv</stringProp>
            <stringProp name="fileEncoding">UTF-8</stringProp>
            <stringProp name="variableNames">username,password</stringProp>
            <boolProp name="recycle">true</boolProp>
            <boolProp name="stopThread">false</boolProp>
            <stringProp name="delimiter">,</stringProp>
          </CSVDataSet>
          
          <!-- ログインリクエスト -->
          <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="ログイン" enabled="true">
            <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
              <collectionProp name="Arguments.arguments">
                <elementProp name="username" elementType="HTTPArgument">
                  <stringProp name="Argument.name">username</stringProp>
                  <stringProp name="Argument.value">${username}</stringProp>
                </elementProp>
                <elementProp name="password" elementType="HTTPArgument">
                  <stringProp name="Argument.name">password</stringProp>
                  <stringProp name="Argument.value">${password}</stringProp>
                </elementProp>
              </collectionProp>
            </elementProp>
            <stringProp name="HTTPSampler.path">/api/v1/auth/login</stringProp>
            <stringProp name="HTTPSampler.method">POST</stringProp>
            <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
            <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
          </HTTPSamplerProxy>
          
          <!-- JSON抽出器（トークン抽出） -->
          <JSONPostProcessor guiclass="JSONPostProcessorGui" testclass="JSONPostProcessor" testname="トークン抽出" enabled="true">
            <stringProp name="JSONPostProcessor.referenceNames">token</stringProp>
            <stringProp name="JSONPostProcessor.jsonPathExprs">$.accessToken</stringProp>
            <stringProp name="JSONPostProcessor.match_numbers">1</stringProp>
          </JSONPostProcessor>
          
          <!-- 案件検索リクエスト -->
          <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="案件検索" enabled="true">
            <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
              <collectionProp name="Arguments.arguments">
                <elementProp name="keyword" elementType="HTTPArgument">
                  <stringProp name="Argument.name">keyword</stringProp>
                  <stringProp name="Argument.value">Javaエンジニア</stringProp>
                </elementProp>
                <elementProp name="status" elementType="HTTPArgument">
                  <stringProp name="Argument.name">status</stringProp>
                  <stringProp name="Argument.value">OPEN</stringProp>
                </elementProp>
              </collectionProp>
            </elementProp>
            <stringProp name="HTTPSampler.path">/api/v1/projects/search</stringProp>
            <stringProp name="HTTPSampler.method">GET</stringProp>
            <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
            <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
            
            <!-- ヘッダマネージャ（認証トークン設定） -->
            <HeaderManager guiclass="HeaderPanel" testclass="HeaderManager" testname="HTTP Headers" enabled="true">
              <collectionProp name="HeaderManager.headers">
                <elementProp name="" elementType="Header">
                  <stringProp name="Header.name">Authorization</stringProp>
                  <stringProp name="Header.value">Bearer ${token}</stringProp>
                </elementProp>
                <elementProp name="" elementType="Header">
                  <stringProp name="Header.name">Content-Type</stringProp>
                  <stringProp name="Header.value">application/json</stringProp>
                </elementProp>
              </collectionProp>
            </HeaderManager>
          </HTTPSamplerProxy>
          
          <!-- 以下、他の操作を追加 -->
          
          <!-- 結果レポート設定 -->
          <ResultCollector guiclass="ViewResultsFullVisualizer" testclass="ResultCollector" testname="View Results Tree" enabled="true">
            <boolProp name="ResultCollector.error_logging">false</boolProp>
            <objProp>
              <name>saveConfig</name>
              <value class="SampleSaveConfiguration">
                <time>true</time>
                <latency>true</latency>
                <timestamp>true</timestamp>
                <success>true</success>
                <label>true</label>
                <code>true</code>
                <message>true</message>
                <threadName>true</threadName>
                <dataType>true</dataType>
                <encoding>false</encoding>
                <assertions>true</assertions>
                <subresults>true</subresults>
                <responseData>false</responseData>
                <samplerData>false</samplerData>
                <xml>false</xml>
                <fieldNames>true</fieldNames>
                <responseHeaders>false</responseHeaders>
                <requestHeaders>false</requestHeaders>
                <responseDataOnError>false</responseDataOnError>
                <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                <assertionsResultsToSave>0</assertionsResultsToSave>
                <bytes>true</bytes>
                <sentBytes>true</sentBytes>
                <url>true</url>
                <threadCounts>true</threadCounts>
                <idleTime>true</idleTime>
                <connectTime>true</connectTime>
              </value>
            </objProp>
          </ResultCollector>
          
          <ResultCollector guiclass="SummaryReport" testclass="ResultCollector" testname="Summary Report" enabled="true">
            <boolProp name="ResultCollector.error_logging">false</boolProp>
            <objProp>
              <name>saveConfig</name>
              <value class="SampleSaveConfiguration">
                <time>true</time>
                <latency>true</latency>
                <timestamp>true</timestamp>
                <success>true</success>
                <label>true</label>
                <code>true</code>
                <message>true</message>
                <threadName>true</threadName>
                <dataType>true</dataType>
                <encoding>false</encoding>
                <assertions>true</assertions>
                <subresults>true</subresults>
                <responseData>false</responseData>
                <samplerData>false</samplerData>
                <xml>false</xml>
                <fieldNames>true</fieldNames>
                <responseHeaders>false</responseHeaders>
                <requestHeaders>false</requestHeaders>
                <responseDataOnError>false</responseDataOnError>
                <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                <assertionsResultsToSave>0</assertionsResultsToSave>
                <bytes>true</bytes>
                <sentBytes>true</sentBytes>
                <url>true</url>
                <threadCounts>true</threadCounts>
                <idleTime>true</idleTime>
                <connectTime>true</connectTime>
              </value>
            </objProp>
          </ResultCollector>
        </ThreadGroup>
      </hashTree>
    </TestPlan>
  </hashTree>
</jmeterTestPlan>
```

#### 4.4.2 性能テスト実行コマンド例

```bash
# JMeterによる性能テスト実行コマンド例

# GUI無しモードでテスト実行（結果をCSVに出力）
jmeter -n -t load_test_sales_scenario.jmx -l results/sales_scenario_results.csv

# 複数スレッドグループの同時実行
jmeter -n -t load_test_all_users.jmx -l results/all_users_results.csv -j results/jmeter.log

# パラメータ指定での実行（動的なユーザー数、実行時間の変更）
jmeter -n -t load_test_template.jmx -l results/custom_test_results.csv \
       -Jusers=200 -Jrampup=120 -Jduration=1800 \
       -Jhost=test-server.example.com
```

## 5. 結果分析とレポート

### 5.1 パフォーマンス指標と分析方法

#### 5.1.1 主要パフォーマンス指標

以下の指標を中心に性能評価を行う：

1. **応答時間指標**
   - 平均応答時間
   - 90パーセンタイル応答時間
   - 95パーセンタイル応答時間
   - 99パーセンタイル応答時間
   - 最大応答時間

2. **スループット指標**
   - 秒間リクエスト数
   - 秒間トランザクション数
   - 時間あたり処理件数

3. **リソース使用率指標**
   - CPU使用率
   - メモリ使用率
   - ディスクI/O
   - ネットワークI/O
   - データベース接続数

4. **エラー率指標**
   - エラー率（%）
   - タイムアウト数
   - 障害発生数

5. **ビジネス指標**
   - 同時ユーザー数
   - 重要業務処理のスループット
   - バッチ処理完了時間

#### 5.1.2 分析手法

収集したデータを以下の手法で分析する：

1. **時系列分析**
   - 負荷変化に対する応答時間の推移
   - リソース消費の経時変化
   - 延長テスト時のパフォーマンス低下傾向

2. **相関分析**
   - ユーザー数と応答時間の相関
   - スループットとリソース使用率の相関
   - エラー率と負荷レベルの相関

3. **ボトルネック分析**
   - リソース使用率上限到達の特定
   - レスポンスタイム急増ポイントの特定
   - スループット頭打ちポイントの特定

4. **根本原因分析**
   - スロークエリの特定
   - 非効率なプログラム処理の特定
   - リソース競合の特定

5. **トレンド分析**
   - 反復テスト結果の比較
   - バージョン間のパフォーマンス変化
   - チューニング効果の検証

### 5.2 レポート作成

#### 5.2.1 レポート構成

性能テスト結果レポートの標準構成：

1. **エグゼクティブサマリー**
   - テスト目的と範囲
   - 主要な発見事項と結論
   - 要件充足状況の概要
   - 重要な推奨事項

2. **テスト概要**
   - テスト環境構成
   - テストシナリオと条件
   - テスト実施期間と日時
   - 実施したテストの種類

3. **テスト結果詳細**
   - シナリオ別の結果数値と目標比較
   - 負荷増加に対する挙動の分析
   - ボトルネックと制限要因の特定
   - エラーパターンと発生条件

4. **リソース使用状況分析**
   - コンポーネント別のリソース消費状況
   - 最大使用率と余裕度
   - スケーラビリティの評価
   - 将来の容量予測

5. **問題点と解決策**
   - 特定された性能課題のリスト
   - 影響度と緊急度評価
   - 推奨される対応策
   - チューニングの優先順位提案

6. **付録**
   - 詳細なテストデータと統計
   - グラフとチャート
   - エラーログと分析
   - テスト環境の詳細構成

#### 5.2.2 レポートサンプル

```markdown
# 性能テスト結果レポート

## エグゼクティブサマリー

SES業務システムの性能テストを実施した結果、現在の実装は500ユーザーの同時アクセスにおいて大部分の性能目標を達成していることが確認されました。ただし、以下の領域で課題が見つかっています：

1. マッチング検索機能の95パーセンタイル応答時間が目標の5秒を超過（実測値: 7.2秒）
2. 請求書一括生成処理がピーク時に目標処理時間を超過（15分目標に対し23分）
3. 長時間テスト（12時間）後にメモリリークの兆候

### 主要結論
- 現在の構成で300ユーザーまでは全機能が性能目標内で動作
- 500ユーザー時は一部機能を除き性能目標を達成
- データベースクエリの最適化により、上記課題は解決可能と推測

## テスト結果サマリー

| シナリオ | 平均応答時間 | 95%応答時間 | 目標達成状況 |
|--------|------------|-----------|-----------|
| ログイン処理 | 0.7秒 | 1.2秒 | ✅ 達成 |
| 技術者検索 | 2.1秒 | 3.5秒 | ✅ 達成 |
| 案件検索 | 1.8秒 | 2.9秒 | ✅ 達成 |
| マッチング検索 | 4.5秒 | 7.2秒 | ❌ 未達成 |
| 契約書生成 | 5.2秒 | 7.5秒 | ✅ 達成 |
| 請求書生成 | 8.3秒 | 12.1秒 | ✅ 達成 |
| レポート表示 | 3.1秒 | 4.8秒 | ✅ 達成 |
| ダッシュボード表示 | 2.2秒 | 2.9秒 | ✅ 達成 |

## リソース使用状況

### 最大リソース使用率（500ユーザー時）
- CPU使用率: 72% (アプリサーバー), 65% (DBサーバー)
- メモリ使用率: 68% (アプリサーバー), 75% (DBサーバー)
- ディスクI/O: 40% (アプリサーバー), 60% (DBサーバー)
- ネットワーク帯域: 22% (アプリサーバー), 18% (DBサーバー)

## 主要ボトルネック

1. **マッチング検索のクエリ処理**
   - 症状: 大量データ時に応答時間が非線形に増加
   - 原因: インデックスの不足、サブクエリの非効率な処理
   - 対策: スキルテーブルのインデックス追加、クエリの最適化

2. **請求書一括生成処理**
   - 症状: 件数増加時に処理時間が急増
   - 原因: 1件ずつのトランザクション処理、リソース競合
   - 対策: バッチ処理の最適化、並列処理の導入

3. **メモリリーク**
   - 症状: 長時間稼働時のメモリ使用量増加
   - 原因: キャッシュオブジェクトの解放漏れ
   - 対策: キャッシュ管理の見直し、GC調整

## 推奨事項

1. **短期対応（優先度高）**
   - マッチング検索クエリの最適化
   - メモリリークの修正

2. **中期対応**
   - 請求書生成処理の並列化
   - データベースコネクションプールの拡大

3. **長期対応**
   - 将来の負荷増加に備えたスケーリング計画
   - 定期的な性能モニタリングと対策の自動化
```

### 5.3 結果に基づく改善プロセス

性能テスト結果から改善までのプロセス：

1. **問題の特定**
   - 性能テスト結果からボトルネックや性能問題を特定
   - データに基づいた優先順位付け

2. **根本原因分析**
   - プロファイリングツールによる詳細分析
   - コードレビューや設計見直し
   - 類似パターンの調査

3. **改善策の立案**
   - 短期的対応と長期的対応の区別
   - 複数の選択肢と影響度評価
   - コスト対効果の分析

4. **改善の実施**
   - 変更の実装
   - 単体レベルでの効果確認
   - 影響範囲の確認

5. **効果検証**
   - 改善前後の性能比較テスト
   - 期待した効果の達成度測定
   - 副作用の確認

6. **文書化と共有**
   - 問題と解決策の文書化
   - 学習事項の共有
   - 将来的な再発防止策の提案

## 6. 性能改善アプローチ

### 6.1 アプリケーションレベルの改善

#### 6.1.1 コード最適化

以下の観点からコード最適化を行う：

1. **アルゴリズム改善**
   - 計算量の少ないアルゴリズムへの変更
   - 不要な処理の削減
   - データ構造の最適化

2. **キャッシュ活用**
   - 読み取り頻度の高いデータのキャッシュ
   - 結果セットキャッシュ
   - 分散キャッシュの導入

3. **非同期処理**
   - ブロッキング処理の非同期化
   - 長時間処理のバックグラウンド実行
   - イベント駆動アーキテクチャの活用

4. **バッチ処理最適化**
   - チャンク処理の導入
   - 並列処理の実装
   - 増分処理の導入

#### 6.1.2 データアクセス最適化

以下の観点からデータアクセスを最適化する：

1. **SQLクエリ最適化**
   - 実行計画の分析と改善
   - インデックスの適切な設計
   - 結合操作の最適化
   - サブクエリの見直し

2. **N+1問題対策**
   - バッチ取得の実装
   - イーガーロードとレイジーロードの適切な使い分け
   - クエリ結合の活用

3. **コネクション管理**
   - コネクションプールの最適化
   - トランザクションの適切なスコープ設定
   - 長時間トランザクションの回避

4. **ORM最適化**
   - エンティティグラフの最適化
   - キャッシュ戦略の調整
   - 必要最小限のデータ取得

### 6.2 インフラストラクチャレベルの改善

#### 6.2.1 サーバーリソース最適化

以下の観点からサーバーリソースを最適化する：

1. **JVMチューニング**
   - ヒープサイズの最適化
   - GCアルゴリズムと設定の調整
   - JITコンパイラの最適化

2. **スレッドプール調整**
   - アプリケーションサーバーのスレッド設定
   - 適切なタイムアウト設定
   - スレッド監視の強化

3. **サーバー構成の最適化**
   - CPU、メモリの適切な割り当て
   - I/Oパフォーマンスの向上
   - ネットワーク設定の最適化

#### 6.2.2 データベース最適化

以下の観点からデータベースを最適化する：

1. **インデックス設計**
   - 適切なインデックスの追加
   - 複合インデックスの活用
   - インデックス使用状況の監視

2. **パーティショニング**
   - 適切なパーティション戦略の導入
   - パーティションプルーニングの最適化
   - データ分布の最適化

3. **設定チューニング**
   - バッファ・キャッシュサイズの調整
   - クエリタイムアウトの設定
   - 自動バキューム設定の最適化

#### 6.2.3 スケーリング戦略

以下のスケーリング戦略を検討する：

1. **水平スケーリング**
   - アプリケーションサーバーの追加
   - ロードバランシングの最適化
   - セッション管理の分散対応

2. **垂直スケーリング**
   - より高性能なハードウェアへの移行
   - リソース増強のタイミング計画
   - コスト対効果の検討

3. **機能分割**
   - 高負荷コンポーネントの分離
   - マイクロサービス化の検討
   - 読み取り/書き込み分離パターンの検討

### 6.3 改善事例と効果予測

主要な性能問題とその改善例：

| 問題 | 改善策 | 期待効果 | 実装コスト |
|-----|-------|---------|----------|
| マッチング検索の遅延 | ・スキルテーブルのインデックス追加<br>・クエリの書き換え<br>・検索結果キャッシュ導入 | 応答時間50%削減 | 中 |
| バッチ処理の長時間化 | ・並列処理の導入<br>・チャンク処理の実装<br>・不要なDB書き込みの削減 | 処理時間60%削減 | 中 |
| DBコネクション枯渇 | ・コネクションプール拡大<br>・不要なトランザクションの短縮<br>・読み取り専用トランザクションの活用 | 同時処理数30%向上 | 低 |
| メモリリーク | ・キャッシュライフサイクル管理の改善<br>・参照解放の徹底<br>・JVMパラメータ調整 | 長時間安定稼働の実現 | 中 |
| レポート生成の遅延 | ・集計テーブルの導入<br>・事前計算の実施<br>・非同期レポート生成 | 応答時間70%削減 | 高 |

## 7. 実施スケジュールとマイルストーン

### 7.1 全体スケジュール

| フェーズ | 期間 | 主要タスク |
|--------|------|----------|
| 準備フェーズ | 2025/07/15 - 2025/07/31 | ・テスト環境構築<br>・テスト用データセット作成<br>・テストツール構成<br>・テストスクリプト開発 |
| 初期性能評価 | 2025/08/01 - 2025/08/15 | ・基本負荷テスト<br>・シナリオテスト<br>・初期ボトルネック特定<br>・リスク評価 |
| 性能改善サイクル | 2025/08/16 - 2025/10/15 | ・優先順位付け<br>・改善実装<br>・検証テスト<br>・効果分析 |
| 最終検証 | 2025/10/16 - 2025/10/31 | ・統合負荷テスト<br>・ユーザー受入テスト<br>・最終レポート作成<br>・本番運用推奨事項のまとめ |

### 7.2 マイルストーン

| マイルストーン | 予定日 | 成果物 |
|--------------|------|-------|
| テスト環境構築完了 | 2025/07/31 | ・構成済みテスト環境<br>・テストデータセット<br>・テスト環境検証レポート |
| 初期テスト完了 | 2025/08/15 | ・初期性能テストレポート<br>・ボトルネック分析結果<br>・改善優先順位リスト |
| 第1回改善サイクル完了 | 2025/09/05 | ・改善実装（優先度高）<br>・検証テスト結果<br>・改善効果レポート |
| 第2回改善サイクル完了 | 2025/09/30 | ・改善実装（優先度中）<br>・検証テスト結果<br>・改善効果レポート |
| 最終テスト完了 | 2025/10/25 | ・最終性能テスト結果<br>・性能要件達成証明<br>・残存課題リスト |
| プロジェクト完了 | 2025/10/31 | ・最終性能テストレポート<br>・本番環境向け推奨構成<br>・モニタリング設計 |

### 7.3 役割と責任

| 役割 | 責任者 | 主な責任 |
|-----|-------|---------|
| 性能テストリード | - | 全体計画、進捗管理、結果評価、報告 |
| テスト環境担当 | - | 環境構築、管理、モニタリング設定 |
| テストスクリプト開発担当 | - | シナリオ設計、スクリプト開発、メンテ |
| 結果分析担当 | - | データ収集、分析、ボトルネック特定 |
| アプリケーション改善担当 | - | コード改善、チューニング、検証 |
| インフラ改善担当 | - | サーバー、DB、ネットワーク調整 |

## 8. リスクと対策

### 8.1 テスト実施のリスク

| リスク | 影響 | 確率 | 対策 |
|-------|------|-----|------|
| テスト環境の性能不足 | 高 | 中 | ・事前に必要スペックを精査<br>・クラウドリソースのスケール機能活用<br>・分散テスト手法の準備 |
| テストデータの不足 | 中 | 中 | ・データ生成スクリプトの事前開発<br>・実データに近いサンプルデータの準備<br>・段階的なデータ量増加テスト |
| テスト工数の不足 | 高 | 中 | ・リスクベースでの優先度明確化<br>・自動化率の向上<br>・並行テスト手法の採用 |
| 環境制約による誤差 | 中 | 高 | ・環境差異の文書化<br>・補正係数の算出と適用<br>・調整可能なパラメータの特定 |
| ツール障害 | 中 | 低 | ・代替ツールの準備<br>・定期的なバックアップ<br>・分散テスト環境の構築 |

### 8.2 性能問題対応のリスク

| リスク | 影響 | 確率 | 対策 |
|-------|------|-----|------|
| 改善効果の不足 | 高 | 中 | ・複数の改善案の並行検討<br>・段階的な改善アプローチ<br>・早期のPoC実施 |
| 改善による副作用 | 高 | 中 | ・変更の影響範囲分析<br>・段階的なテスト戦略<br>・ロールバック計画 |
| スケーリング限界 | 中 | 低 | ・アーキテクチャレビュー<br>・負荷分散戦略の検討<br>・分散アーキテクチャへの移行計画 |
| サードパーティ依存 | 中 | 中 | ・外部サービスのモック化<br>・SLA確認<br>・代替手段の検討 |
| 技術的負債の蓄積 | 中 | 中 | ・技術的負債の可視化<br>・長期改善計画への組み込み<br>・継続的なリファクタリング |

## 9. 参考資料と付録

### 9.1 性能テストに関するリファレンス

- [Performance Testing Guidance for Web Applications (Microsoft)](https://docs.microsoft.com/en-us/previous-versions/msp-n-p/bb924375(v=pandp.10))
- [JMeter User Manual](https://jmeter.apache.org/usermanual/index.html)
- [Gatling Documentation](https://gatling.io/docs/current/)
- [Systems Performance: Enterprise and the Cloud (Brendan Gregg)](https://www.brendangregg.com/systems-performance-2nd-edition-book.html)
- [Database Performance Tuning Guide (PostgreSQL)](https://www.postgresql.org/docs/current/performance-tips.html)
- [Spring Boot Performance Tuning](https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.spring-application.startup-tracking)

### 9.2 JMeterテンプレートとスクリプト

以下のテンプレートをプロジェクトのリポジトリに格納：

- **基本負荷テストテンプレート**: `/performance-test/templates/basic-load-test.jmx`
- **シナリオテストテンプレート**: `/performance-test/templates/scenario-test.jmx`
- **エンドポイント検証テンプレート**: `/performance-test/templates/endpoint-test.jmx`
- **データ生成スクリプト**: `/performance-test/scripts/generate-test-data.sh`
- **結果分析スクリプト**: `/performance-test/scripts/analyze-results.py`

### 9.3 モニタリングダッシュボードサンプル

Grafana ダッシュボードテンプレートを以下のパスに格納：

- **アプリケーションダッシュボード**: `/performance-test/grafana/app-dashboard.json`
- **データベースダッシュボード**: `/performance-test/grafana/db-dashboard.json`
- **JVMダッシュボード**: `/performance-test/grafana/jvm-dashboard.json`
- **エンドポイントパフォーマンスダッシュボード**: `/performance-test/grafana/endpoint-dashboard.json`
- **ビジネスメトリクスダッシュボード**: `/performance-test/grafana/business-dashboard.json`

### 9.4 用語集

- **応答時間 (Response Time)**: リクエスト送信からレスポンス受信までの時間
- **スループット (Throughput)**: 単位時間あたりの処理件数
- **パーセンタイル (Percentile)**: 全測定値を小さい順に並べたときの割合が示す点（例：95パーセンタイルは上位5%を除いた最大値）
- **コンカレントユーザー (Concurrent Users)**: 同時にシステムを使用しているユーザー数
- **バーチャルユーザー (Virtual Users)**: 負荷テストでシミュレートされるユーザー
- **ボトルネック (Bottleneck)**: システムのパフォーマンスを制限する最も遅い部分
- **ストレステスト (Stress Test)**: システムの限界を見つけるためのテスト
- **耐久テスト (Endurance Test)**: 長時間の安定性を検証するテスト
- **スパイクテスト (Spike Test)**: 突発的な負荷増加への対応を検証するテスト
- **ベースライン (Baseline)**: 比較の基準となる性能測定値