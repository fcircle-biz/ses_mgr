# 検索インデックス管理

## 1. 概要

検索インデックス管理機能は、Spring Data Elasticsearchを活用して検索エンジンで使用されるインデックスを効率的に作成、更新、管理するための機能です。SES管理システムの各種エンティティ（技術者、案件、契約など）に対する検索を最適化し、高速かつ正確な検索結果を提供することを目的としています。

### 1.1 主な機能

- 各種リソース（技術者、案件など）の検索インデックス作成
- インデックスの定期的な更新・再構築
- インデックスのバージョン管理とエイリアス切り替え
- インデックステンプレートの管理
- インデックスの状態監視
- 検索用マッピング定義の管理
- 日本語形態素解析の最適化

## 2. システム構成

検索インデックス管理機能のシステム構成は以下の通りです：

```
IndexManagementSystem
├── IndexManager（インデックス管理コアモジュール）- Spring Data Elasticsearchベース
├── IndexSynchronizer（DB-インデックス同期モジュール）- Spring Data JDBCと連携
├── IndexHealthMonitor（インデックス状態監視モジュール）- Spring Actuatorと連携
├── IndexTemplateManager（テンプレート管理モジュール）- Spring Data Elasticsearchベース
├── MappingDefinitionManager（マッピング定義管理）- Spring Data Elasticsearchベース
└── IndexingBatchProcessor（バッチ処理モジュール）- Spring Batchベース
```

## 3. インデックス設計

### 3.1 インデックス命名規則

```
{リソース種別}-{環境}-{バージョン}
```

例：
- engineers-prod-v1（技術者インデックス、本番環境、バージョン1）
- projects-dev-v2（案件インデックス、開発環境、バージョン2）

### 3.2 エイリアス設計

各インデックスには以下のエイリアスを設定します：

- **{リソース種別}-current**: 現在アクティブなインデックスを指す
- **{リソース種別}-write**: 書き込み用エイリアス
- **{リソース種別}-read**: 読み取り用エイリアス

Spring Data Elasticsearchを使用して、インデックス再構築時には新インデックスの構築完了後にエイリアスを切り替えることで、ダウンタイムゼロでのインデックス更新を実現します。

### 3.3 インデックスライフサイクル

インデックスは以下のライフサイクルで管理されます：

1. **初期化**: Spring Data Elasticsearchを使用してインデックステンプレートとマッピング定義からインデックスを作成
2. **データインポート**: Spring Data ElasticsearchのBulkOperationsを使用して初期データをインデックスにバルクインポート
3. **アクティベーション**: Spring Data Elasticsearchを使用して完成したインデックスにエイリアスを付与して有効化
4. **更新**: Spring ApplicationEventとSpring Data JDBCを使用した定期的な同期処理またはイベント駆動で差分更新
5. **再構築**: Spring Batchを使用して必要に応じて新バージョンで再構築
6. **アーカイブ**: Spring Data Elasticsearchを使用して不要になったインデックスのアーカイブ
7. **削除**: Spring Data Elasticsearchを使用してアーカイブ期間経過後の削除

## 4. リソース別インデックス設計

主要リソースごとに最適化されたインデックス設計を定義します。

### 4.1 技術者（Engineers）インデックス

#### 4.1.1 マッピング定義

```java
@Configuration
public class EngineerIndexConfig {
    
    @Bean
    public IndexConfiguration engineerIndexConfiguration() {
        return new IndexConfiguration.Builder()
            .withName("engineers")
            .withMapping(engineerMapping())
            .withSettings(engineerSettings())
            .build();
    }
    
    private Document engineerMapping() {
        Map<String, Object> mapping = new HashMap<>();
        
        // ID フィールド
        Map<String, Object> idField = new HashMap<>();
        idField.put("type", "keyword");
        mapping.put("id", idField);
        
        // 名前フィールド（日本語テキスト + キーワード）
        Map<String, Object> nameField = new HashMap<>();
        nameField.put("type", "text");
        nameField.put("analyzer", "japanese");
        
        Map<String, Object> keywordField = new HashMap<>();
        keywordField.put("type", "keyword");
        
        Map<String, Object> nameFields = new HashMap<>();
        nameFields.put("keyword", keywordField);
        nameField.put("fields", nameFields);
        
        mapping.put("name", nameField);
        
        // かなフィールド
        Map<String, Object> kanaField = new HashMap<>();
        kanaField.put("type", "text");
        kanaField.put("analyzer", "standard");
        mapping.put("kana", kanaField);
        
        // スキルフィールド（ネスト型）
        Map<String, Object> skillNameField = new HashMap<>();
        skillNameField.put("type", "keyword");
        
        Map<String, Object> skillLevelField = new HashMap<>();
        skillLevelField.put("type", "integer");
        
        Map<String, Object> skillYearsField = new HashMap<>();
        skillYearsField.put("type", "float");
        
        Map<String, Object> skillProperties = new HashMap<>();
        skillProperties.put("name", skillNameField);
        skillProperties.put("level", skillLevelField);
        skillProperties.put("years", skillYearsField);
        
        Map<String, Object> skillsField = new HashMap<>();
        skillsField.put("type", "nested");
        skillsField.put("properties", skillProperties);
        
        mapping.put("skills", skillsField);
        
        // 他のフィールド定義...
        
        return Document.from(mapping);
    }
    
    private Document engineerSettings() {
        Map<String, Object> settings = new HashMap<>();
        
        // シャード設定
        settings.put("number_of_shards", 3);
        settings.put("number_of_replicas", 1);
        
        // 解析器設定
        Map<String, Object> analysis = new HashMap<>();
        Map<String, Object> analyzers = new HashMap<>();
        
        // 日本語アナライザー設定
        Map<String, Object> japaneseAnalyzer = new HashMap<>();
        japaneseAnalyzer.put("type", "custom");
        japaneseAnalyzer.put("tokenizer", "kuromoji_tokenizer");
        
        List<String> filters = new ArrayList<>();
        filters.add("kuromoji_baseform");
        filters.add("kuromoji_part_of_speech");
        filters.add("ja_stop");
        filters.add("kuromoji_number");
        filters.add("kuromoji_stemmer");
        
        japaneseAnalyzer.put("filter", filters);
        analyzers.put("japanese", japaneseAnalyzer);
        analysis.put("analyzer", analyzers);
        
        settings.put("analysis", analysis);
        
        return Document.from(settings);
    }
}
```

### 4.2 案件（Projects）インデックス

#### 4.2.1 マッピング定義

```java
@Configuration
public class ProjectIndexConfig {
    
    @Bean
    public IndexConfiguration projectIndexConfiguration() {
        return new IndexConfiguration.Builder()
            .withName("projects")
            .withMapping(projectMapping())
            .withSettings(projectSettings())
            .build();
    }
    
    private Document projectMapping() {
        Map<String, Object> mapping = new HashMap<>();
        
        // ID フィールド
        Map<String, Object> idField = new HashMap<>();
        idField.put("type", "keyword");
        mapping.put("id", idField);
        
        // タイトルフィールド（日本語テキスト + キーワード）
        Map<String, Object> titleField = new HashMap<>();
        titleField.put("type", "text");
        titleField.put("analyzer", "japanese");
        
        Map<String, Object> keywordField = new HashMap<>();
        keywordField.put("type", "keyword");
        
        Map<String, Object> titleFields = new HashMap<>();
        titleFields.put("keyword", keywordField);
        titleField.put("fields", titleFields);
        
        mapping.put("title", titleField);
        
        // 説明フィールド
        Map<String, Object> descriptionField = new HashMap<>();
        descriptionField.put("type", "text");
        descriptionField.put("analyzer", "japanese");
        mapping.put("description", descriptionField);
        
        // 要求スキルフィールド（ネスト型）
        Map<String, Object> skillNameField = new HashMap<>();
        skillNameField.put("type", "keyword");
        
        Map<String, Object> skillLevelField = new HashMap<>();
        skillLevelField.put("type", "integer");
        
        Map<String, Object> skillRequiredField = new HashMap<>();
        skillRequiredField.put("type", "boolean");
        
        Map<String, Object> skillProperties = new HashMap<>();
        skillProperties.put("name", skillNameField);
        skillProperties.put("level", skillLevelField);
        skillProperties.put("required", skillRequiredField);
        
        Map<String, Object> requiredSkillsField = new HashMap<>();
        requiredSkillsField.put("type", "nested");
        requiredSkillsField.put("properties", skillProperties);
        
        mapping.put("requiredSkills", requiredSkillsField);
        
        // 他のフィールド定義...
        
        return Document.from(mapping);
    }
    
    private Document projectSettings() {
        // エンジニアインデックスと同様の設定を使用
        return engineerIndexConfig.engineerSettings();
    }
    
    @Autowired
    private EngineerIndexConfig engineerIndexConfig;
}
```

## 5. インデックス同期処理

### 5.1 同期方式

インデックスとデータベースの同期は以下の方式で実施します：

1. **バッチ同期**: Spring Batchを使用した定期的なバッチ処理による全件または差分同期
2. **イベント駆動同期**: Spring ApplicationEventベースのデータ変更イベントをトリガーにしたリアルタイム同期
3. **ハイブリッド同期**: イベント駆動と定期バッチのハイブリッド方式

### 5.2 同期処理フロー

```java
@Service
@RequiredArgsConstructor
public class IndexSynchronizerService {
    
    private final ElasticsearchOperations elasticsearchOperations;
    private final IndexingEventRepository eventRepository;
    private final Map<String, ResourceDataProvider> resourceDataProviders;
    
    @Transactional
    @EventListener(DataChangeEvent.class)
    public void handleDataChangeEvent(DataChangeEvent event) {
        // イベントをキューに格納
        IndexingEvent indexingEvent = new IndexingEvent();
        indexingEvent.setResourceType(event.getResourceType());
        indexingEvent.setResourceId(event.getResourceId());
        indexingEvent.setChangeType(event.getChangeType().toString());
        indexingEvent.setTimestamp(LocalDateTime.now());
        indexingEvent.setStatus("PENDING");
        
        eventRepository.save(indexingEvent);
    }
    
    @Scheduled(fixedDelay = 5000) // 5秒ごとに実行
    @Transactional
    public void processPendingEvents() {
        List<IndexingEvent> pendingEvents = eventRepository.findByStatusOrderByTimestamp("PENDING", Pageable.ofSize(100));
        
        if (pendingEvents.isEmpty()) {
            return;
        }
        
        // イベントをバッチ処理
        Map<String, BulkOperations> bulkOperationsMap = new HashMap<>();
        
        for (IndexingEvent event : pendingEvents) {
            try {
                String resourceType = event.getResourceType();
                String resourceId = event.getResourceId();
                
                // 対応するリソースプロバイダーを取得
                ResourceDataProvider provider = resourceDataProviders.get(resourceType);
                if (provider == null) {
                    event.setStatus("ERROR");
                    event.setErrorMessage("Unknown resource type: " + resourceType);
                    continue;
                }
                
                // バルク操作の取得または作成
                BulkOperations bulkOps = bulkOperationsMap.computeIfAbsent(resourceType,
                    type -> elasticsearchOperations.bulkOps(BulkOperations.BulkMode.PARTIAL_UPDATE, 
                                                         Class.forName(provider.getEntityClass())));
                
                // イベントタイプに応じた処理
                switch (event.getChangeType()) {
                    case "CREATE":
                    case "UPDATE":
                        Map<String, Object> resourceData = provider.getResourceById(resourceId);
                        if (resourceData != null) {
                            bulkOps.upsert(IndexQuery.builder()
                                  .withId(resourceId)
                                  .withObject(resourceData)
                                  .build());
                        }
                        break;
                    case "DELETE":
                        bulkOps.delete(resourceId);
                        break;
                }
                
                event.setStatus("PROCESSED");
            } catch (Exception e) {
                event.setStatus("ERROR");
                event.setErrorMessage(e.getMessage());
            }
        }
        
        // バルク操作の実行
        for (Map.Entry<String, BulkOperations> entry : bulkOperationsMap.entrySet()) {
            try {
                entry.getValue().execute();
            } catch (Exception e) {
                log.error("Error executing bulk operations for resource type {}: {}", 
                         entry.getKey(), e.getMessage(), e);
                // 対応するイベントをエラーマークする
                pendingEvents.stream()
                    .filter(event -> event.getResourceType().equals(entry.getKey()) && 
                                   "PROCESSED".equals(event.getStatus()))
                    .forEach(event -> {
                        event.setStatus("ERROR");
                        event.setErrorMessage("Bulk operation failed: " + e.getMessage());
                    });
            }
        }
        
        // イベントステータスの更新
        eventRepository.saveAll(pendingEvents);
    }
}
```

### 5.3 差分検出ロジック

差分検出は以下の方法で実施します：

1. **タイムスタンプベース**: Spring Data JDBCを使用して最終同期時刻以降に更新されたレコードを抽出
2. **バージョンベース**: Spring Data JDBCのバージョニング機能を利用したレコードバージョン番号での差分検出
3. **イベントログベース**: Spring Data JDBCのイベントリスナーとApplicationEventを活用したDB変更イベントログからの差分抽出

```java
@Repository
public interface EngineerRepository extends CrudRepository<Engineer, UUID> {

    /**
     * 最終更新日時以降に更新されたエンジニアを取得
     */
    @Query("SELECT * FROM engineers WHERE last_updated > :lastSyncTime ORDER BY last_updated ASC LIMIT :limit")
    List<Engineer> findUpdatedSince(@Param("lastSyncTime") LocalDateTime lastSyncTime, @Param("limit") int limit);
}
```

## 6. インデックス再構築処理

### 6.1 再構築フロー

```java
@Component
@RequiredArgsConstructor
public class IndexRebuildService {

    private final ElasticsearchOperations elasticsearchOperations;
    private final ElasticsearchRestTemplate restTemplate;
    private final Map<String, ResourceDataProvider> resourceDataProviders;
    private final Map<String, IndexConfiguration> indexConfigurations;
    
    /**
     * 指定されたリソースタイプのインデックスを再構築する
     */
    @Async
    public CompletableFuture<String> rebuildIndex(String resourceType) {
        String jobId = UUID.randomUUID().toString();
        
        try {
            // リソースプロバイダーの取得
            ResourceDataProvider provider = resourceDataProviders.get(resourceType);
            if (provider == null) {
                throw new IllegalArgumentException("Unknown resource type: " + resourceType);
            }
            
            // インデックス設定の取得
            IndexConfiguration config = indexConfigurations.get(resourceType);
            if (config == null) {
                throw new IllegalArgumentException("Index configuration not found for resource type: " + resourceType);
            }
            
            // 新しいインデックス名の生成（バージョン付き）
            String currentVersion = getCurrentIndexVersion(resourceType);
            int newVersion = currentVersion != null ? 
                            Integer.parseInt(currentVersion.substring(1)) + 1 : 1;
            String newIndexName = resourceType + "-" + "v" + newVersion;
            
            // 新しいインデックスの作成
            createNewIndex(newIndexName, config);
            
            // データの取得と変換
            AtomicInteger counter = new AtomicInteger(0);
            List<IndexQuery> bulkQueries = new ArrayList<>();
            
            provider.streamAllResources(resourceData -> {
                String id = resourceData.get("id").toString();
                bulkQueries.add(IndexQuery.builder()
                             .withId(id)
                             .withObject(resourceData)
                             .withIndex(newIndexName)
                             .build());
                
                // 1000件ごとにバルク処理を実行
                if (counter.incrementAndGet() % 1000 == 0) {
                    elasticsearchOperations.bulkIndex(bulkQueries, BulkOptions.defaultOptions(), Document.class);
                    bulkQueries.clear();
                }
            });
            
            // 残りのクエリを処理
            if (!bulkQueries.isEmpty()) {
                elasticsearchOperations.bulkIndex(bulkQueries, BulkOptions.defaultOptions(), Document.class);
            }
            
            // インデックスの検証
            boolean valid = validateIndex(newIndexName, counter.get());
            if (!valid) {
                throw new IllegalStateException("Index validation failed for " + newIndexName);
            }
            
            // エイリアスの切り替え
            switchAliases(resourceType, newIndexName);
            
            return CompletableFuture.completedFuture(jobId);
            
        } catch (Exception e) {
            CompletableFuture<String> future = new CompletableFuture<>();
            future.completeExceptionally(e);
            return future;
        }
    }
    
    /**
     * 現在のインデックスバージョンを取得
     */
    private String getCurrentIndexVersion(String resourceType) {
        try {
            GetAliasesRequest request = new GetAliasesRequest(resourceType + "-current");
            GetAliasesResponse response = restTemplate.execute(client -> 
                client.indices().getAlias(request, RequestOptions.DEFAULT));
                
            if (response.getAliases().isEmpty()) {
                return null;
            }
            
            // エイリアスが指すインデックス名から最新バージョンを抽出
            String indexName = response.getAliases().keySet().iterator().next();
            return indexName.substring(indexName.lastIndexOf("-") + 1);
            
        } catch (Exception e) {
            return null;
        }
    }
    
    /**
     * 新しいインデックスを作成
     */
    private void createNewIndex(String indexName, IndexConfiguration config) {
        IndexCoordinates coordinates = IndexCoordinates.of(indexName);
        
        // インデックスの作成
        CreateIndexRequest createRequest = new CreateIndexRequest(indexName);
        createRequest.settings(config.getSettings());
        createRequest.mapping(config.getMapping());
        
        restTemplate.execute(client -> 
            client.indices().create(createRequest, RequestOptions.DEFAULT));
    }
    
    /**
     * インデックスの検証
     */
    private boolean validateIndex(String indexName, int expectedCount) {
        try {
            // ドキュメント数の確認
            CountRequest countRequest = new CountRequest(indexName);
            CountResponse countResponse = restTemplate.execute(client -> 
                client.count(countRequest, RequestOptions.DEFAULT));
                
            long actualCount = countResponse.getCount();
            
            if (actualCount < expectedCount * 0.95) { // 5%の誤差は許容
                return false;
            }
            
            // インデックスの健全性チェック
            ClusterHealthRequest healthRequest = new ClusterHealthRequest(indexName);
            healthRequest.waitForStatus(ClusterHealthStatus.YELLOW);
            ClusterHealthResponse healthResponse = restTemplate.execute(client -> 
                client.cluster().health(healthRequest, RequestOptions.DEFAULT));
                
            return !healthResponse.isTimedOut() && 
                  (healthResponse.getStatus() == ClusterHealthStatus.GREEN || 
                   healthResponse.getStatus() == ClusterHealthStatus.YELLOW);
                   
        } catch (Exception e) {
            return false;
        }
    }
    
    /**
     * エイリアスの切り替え
     */
    private void switchAliases(String resourceType, String newIndexName) {
        // 既存のエイリアスの対象インデックスを取得
        String currentAlias = resourceType + "-current";
        String writeAlias = resourceType + "-write";
        String readAlias = resourceType + "-read";
        
        String oldIndexName = null;
        try {
            GetAliasesRequest request = new GetAliasesRequest(currentAlias);
            GetAliasesResponse response = restTemplate.execute(client -> 
                client.indices().getAlias(request, RequestOptions.DEFAULT));
                
            if (!response.getAliases().isEmpty()) {
                oldIndexName = response.getAliases().keySet().iterator().next();
            }
        } catch (Exception e) {
            // エイリアスが存在しない場合は無視
        }
        
        // エイリアス切り替え操作
        IndicesAliasesRequest aliasesRequest = new IndicesAliasesRequest();
        
        // 既存のエイリアスを削除
        if (oldIndexName != null) {
            aliasesRequest.addAliasAction(
                IndicesAliasesRequest.AliasActions.remove()
                    .index(oldIndexName)
                    .alias(currentAlias));
            aliasesRequest.addAliasAction(
                IndicesAliasesRequest.AliasActions.remove()
                    .index(oldIndexName)
                    .alias(writeAlias));
            aliasesRequest.addAliasAction(
                IndicesAliasesRequest.AliasActions.remove()
                    .index(oldIndexName)
                    .alias(readAlias));
        }
        
        // 新しいエイリアスを追加
        aliasesRequest.addAliasAction(
            IndicesAliasesRequest.AliasActions.add()
                .index(newIndexName)
                .alias(currentAlias));
        aliasesRequest.addAliasAction(
            IndicesAliasesRequest.AliasActions.add()
                .index(newIndexName)
                .alias(writeAlias));
        aliasesRequest.addAliasAction(
            IndicesAliasesRequest.AliasActions.add()
                .index(newIndexName)
                .alias(readAlias));
                
        // アトミックな操作でエイリアス切り替えを実行
        restTemplate.execute(client -> 
            client.indices().updateAliases(aliasesRequest, RequestOptions.DEFAULT));
            
        // 古いインデックスをアーカイブ（オプション）
        if (oldIndexName != null) {
            archiveIndex(oldIndexName);
        }
    }
    
    /**
     * 古いインデックスをアーカイブ
     */
    private void archiveIndex(String indexName) {
        // インデックス設定の更新（読み取り専用に）
        UpdateSettingsRequest updateRequest = new UpdateSettingsRequest(indexName);
        Settings settings = Settings.builder()
                         .put("index.blocks.write", true)
                         .build();
        updateRequest.settings(settings);
        
        try {
            restTemplate.execute(client -> 
                client.indices().putSettings(updateRequest, RequestOptions.DEFAULT));
        } catch (Exception e) {
            log.warn("Failed to archive index {}: {}", indexName, e.getMessage());
        }
    }
}
```

### 6.2 ゼロダウンタイム切り替え

エイリアスを使用したゼロダウンタイム切り替えは、前述のindexRebuildメソッド内のswitchAliasesメソッドで実装されています。Spring Data ElasticsearchのIndicesAliasesRequestを使用して、アトミックな操作ですべてのエイリアスを一度に切り替えます。

## 7. インデックス状態監視

### 7.1 監視項目

以下の項目を定期的に監視します：

- インデックスサイズとシャード状態
- インデックス処理パフォーマンス（インデックス作成・検索レスポンス時間）
- インデックスの同期遅延
- シャードの割り当て状態
- ノード状態
- ディスク使用率

```java
@Component
@RequiredArgsConstructor
public class IndexHealthMonitor {
    
    private final ElasticsearchRestTemplate restTemplate;
    private final MeterRegistry meterRegistry;
    private final IndexingEventRepository eventRepository;
    
    @Scheduled(fixedRate = 60000) // 1分ごとに実行
    public void monitorIndices() {
        try {
            // インデックス統計情報を取得
            IndicesStatsRequest statsRequest = new IndicesStatsRequest();
            IndicesStatsResponse statsResponse = restTemplate.execute(client -> 
                client.indices().stats(statsRequest, RequestOptions.DEFAULT));
                
            // クラスタヘルス情報を取得
            ClusterHealthRequest healthRequest = new ClusterHealthRequest();
            ClusterHealthResponse healthResponse = restTemplate.execute(client -> 
                client.cluster().health(healthRequest, RequestOptions.DEFAULT));
                
            // ノード情報を取得
            NodesInfoRequest infoRequest = new NodesInfoRequest();
            infoRequest.clear().addMetric(NodesInfoRequest.Metric.OS.metricName());
            infoRequest.addMetric(NodesInfoRequest.Metric.JVM.metricName());
            infoRequest.addMetric(NodesInfoRequest.Metric.PROCESS.metricName());
            NodesInfoResponse infoResponse = restTemplate.execute(client -> 
                client.nodes().info(infoRequest, RequestOptions.DEFAULT));
                
            // メトリクスの記録
            recordClusterMetrics(healthResponse);
            recordIndicesMetrics(statsResponse);
            recordNodeMetrics(infoResponse);
            recordSyncDelayMetrics();
            
        } catch (Exception e) {
            log.error("Failed to monitor Elasticsearch indices: {}", e.getMessage(), e);
        }
    }
    
    /**
     * クラスタメトリクスの記録
     */
    private void recordClusterMetrics(ClusterHealthResponse response) {
        meterRegistry.gauge("elasticsearch.cluster.status", 
                    response.getStatus() == ClusterHealthStatus.GREEN ? 0 : 
                    response.getStatus() == ClusterHealthStatus.YELLOW ? 1 : 2);
        meterRegistry.gauge("elasticsearch.cluster.node_count", response.getNumberOfNodes());
        meterRegistry.gauge("elasticsearch.cluster.active_shards", response.getActiveShards());
        meterRegistry.gauge("elasticsearch.cluster.relocating_shards", response.getRelocatingShards());
        meterRegistry.gauge("elasticsearch.cluster.initializing_shards", response.getInitializingShards());
        meterRegistry.gauge("elasticsearch.cluster.unassigned_shards", response.getUnassignedShards());
    }
    
    /**
     * インデックスメトリクスの記録
     */
    private void recordIndicesMetrics(IndicesStatsResponse response) {
        // 全インデックスの合計サイズ
        meterRegistry.gauge("elasticsearch.indices.total_size_bytes", 
                    response.getTotal().getStore().getSizeInBytes());
                    
        // インデックスごとのメトリクス
        response.getIndices().forEach((indexName, stats) -> {
            String sanitizedName = indexName.replaceAll("[^a-zA-Z0-9]", "_");
            
            meterRegistry.gauge("elasticsearch.index." + sanitizedName + ".size_bytes", 
                        stats.getTotal().getStore().getSizeInBytes());
            meterRegistry.gauge("elasticsearch.index." + sanitizedName + ".document_count", 
                        stats.getTotal().getDocs().getCount());
            meterRegistry.gauge("elasticsearch.index." + sanitizedName + ".query_total", 
                        stats.getTotal().getSearch().getQueryTotal());
            meterRegistry.gauge("elasticsearch.index." + sanitizedName + ".query_time_ms", 
                        stats.getTotal().getSearch().getQueryTimeInMillis());
        });
    }
    
    /**
     * ノードメトリクスの記録
     */
    private void recordNodeMetrics(NodesInfoResponse response) {
        response.getNodes().forEach((nodeId, nodeInfo) -> {
            String nodeName = nodeInfo.getName().replaceAll("[^a-zA-Z0-9]", "_");
            
            // JVMメトリクス
            meterRegistry.gauge("elasticsearch.node." + nodeName + ".jvm.heap_max_bytes", 
                        nodeInfo.getJvm().getMem().getHeapMax().getBytes());
            meterRegistry.gauge("elasticsearch.node." + nodeName + ".jvm.heap_used_bytes", 
                        nodeInfo.getJvm().getMem().getHeapUsed().getBytes());
                        
            // OSメトリクス
            meterRegistry.gauge("elasticsearch.node." + nodeName + ".os.cpu_percent", 
                        nodeInfo.getProcess().getCpu().getPercent());
            meterRegistry.gauge("elasticsearch.node." + nodeName + ".os.mem_total_bytes", 
                        nodeInfo.getOs().getMem().getTotal().getBytes());
            meterRegistry.gauge("elasticsearch.node." + nodeName + ".os.mem_free_bytes", 
                        nodeInfo.getOs().getMem().getFree().getBytes());
        });
    }
    
    /**
     * 同期遅延メトリクスの記録
     */
    private void recordSyncDelayMetrics() {
        // 未処理のイベント数を取得
        long pendingCount = eventRepository.countByStatus("PENDING");
        meterRegistry.gauge("elasticsearch.sync.pending_events", pendingCount);
        
        // 最も古い未処理イベントの遅延を計算
        Optional<IndexingEvent> oldestEvent = eventRepository.findTopByStatusOrderByTimestampAsc("PENDING");
        if (oldestEvent.isPresent()) {
            Duration delay = Duration.between(oldestEvent.get().getTimestamp(), LocalDateTime.now());
            meterRegistry.gauge("elasticsearch.sync.oldest_event_delay_seconds", delay.getSeconds());
        } else {
            meterRegistry.gauge("elasticsearch.sync.oldest_event_delay_seconds", 0);
        }
    }
}
```

### 7.2 アラート設定

| 監視項目 | 閾値 | アラートレベル |
|---------|------|--------------|
| 同期遅延 | 5分以上 | 警告 |
| 同期遅延 | 30分以上 | 重大 |
| インデックスサイズ | 予測の120%以上 | 警告 |
| シャード未割当て | 5分以上 | 重大 |
| ノードダウン | 即時 | 重大 |
| ディスク使用率 | 85%以上 | 警告 |
| ディスク使用率 | 95%以上 | 重大 |

## 8. 日本語形態素解析の最適化

### 8.1 kuromoji設定

日本語検索を最適化するためのkuromojiアナライザー設定をSpring Data Elasticsearchで実装します：

```java
@Configuration
public class JapaneseAnalysisConfig {

    @Bean
    public ElasticsearchCustomConversions elasticsearchCustomConversions() {
        return new ElasticsearchCustomConversions(
            Collections.singletonList(new JapaneseAnalysisConverter()));
    }
    
    public static class JapaneseAnalysisConverter {
        
        public Map<String, Object> createJapaneseAnalysisSettings() {
            Map<String, Object> settings = new HashMap<>();
            Map<String, Object> analysis = new HashMap<>();
            
            // アナライザー設定
            Map<String, Object> analyzers = new HashMap<>();
            Map<String, Object> japaneseAnalyzer = new HashMap<>();
            japaneseAnalyzer.put("type", "custom");
            japaneseAnalyzer.put("tokenizer", "kuromoji_tokenizer");
            
            List<String> charFilters = new ArrayList<>();
            charFilters.add("icu_normalizer");
            charFilters.add("japanese_iteration_mark");
            japaneseAnalyzer.put("char_filter", charFilters);
            
            List<String> filters = new ArrayList<>();
            filters.add("kuromoji_baseform");
            filters.add("kuromoji_part_of_speech");
            filters.add("ja_stop");
            filters.add("kuromoji_number");
            filters.add("kuromoji_stemmer");
            japaneseAnalyzer.put("filter", filters);
            
            analyzers.put("japanese_analyzer", japaneseAnalyzer);
            analysis.put("analyzer", analyzers);
            
            // 文字フィルター設定
            Map<String, Object> charFilterDefs = new HashMap<>();
            Map<String, Object> iterationMark = new HashMap<>();
            iterationMark.put("type", "mapping");
            iterationMark.put("mappings", Collections.singletonList("々=>\\u306e"));
            charFilterDefs.put("japanese_iteration_mark", iterationMark);
            analysis.put("char_filter", charFilterDefs);
            
            settings.put("analysis", analysis);
            return settings;
        }
    }
}
```

### 8.2 ユーザー辞書管理

専門用語や固有名詞を適切に処理するためのユーザー辞書を管理します：

```java
@Service
@RequiredArgsConstructor
public class DictionaryService {

    private final ElasticsearchRestTemplate restTemplate;
    private final ResourceLoader resourceLoader;
    
    /**
     * ユーザー辞書をElasticsearchに登録
     */
    @PostConstruct
    public void loadUserDictionary() {
        try {
            Resource dictResource = resourceLoader.getResource("classpath:dictionary/user_dictionary.txt");
            if (!dictResource.exists()) {
                log.warn("User dictionary not found at classpath:dictionary/user_dictionary.txt");
                return;
            }
            
            byte[] dictionaryContent = FileCopyUtils.copyToByteArray(dictResource.getInputStream());
            
            PutSettingsRequest request = new PutSettingsRequest("*");
            Settings settings = Settings.builder()
                             .putList("index.analysis.analyzer.japanese_analyzer.tokenizer", "kuromoji_tokenizer")
                             .putList("index.analysis.tokenizer.kuromoji_tokenizer.mode", "search")
                             .putList("index.analysis.tokenizer.kuromoji_tokenizer.user_dictionary", "user_dict")
                             .put("index.analysis.tokenizer.kuromoji_tokenizer.user_dictionary_rules", 
                                 new String(dictionaryContent, StandardCharsets.UTF_8))
                             .build();
            request.settings(settings);
            
            restTemplate.execute(client -> 
                client.indices().putSettings(request, RequestOptions.DEFAULT));
                
            log.info("User dictionary loaded successfully");
            
        } catch (Exception e) {
            log.error("Failed to load user dictionary: {}", e.getMessage(), e);
        }
    }
    
    /**
     * ユーザー辞書を更新
     */
    @Transactional
    public void updateUserDictionary(String dictionaryContent) {
        try {
            // 辞書ファイルの更新
            Resource dictResource = resourceLoader.getResource("classpath:dictionary/user_dictionary.txt");
            if (dictResource instanceof WritableResource) {
                WritableResource writableResource = (WritableResource) dictResource;
                try (Writer writer = new OutputStreamWriter(writableResource.getOutputStream(), StandardCharsets.UTF_8)) {
                    writer.write(dictionaryContent);
                }
            } else {
                throw new IllegalStateException("Dictionary resource is not writable");
            }
            
            // Elasticsearchへの辞書再適用
            PutSettingsRequest request = new PutSettingsRequest("*");
            Settings settings = Settings.builder()
                             .put("index.analysis.tokenizer.kuromoji_tokenizer.user_dictionary_rules", 
                                 dictionaryContent)
                             .build();
            request.settings(settings);
            
            restTemplate.execute(client -> 
                client.indices().putSettings(request, RequestOptions.DEFAULT));
                
            // すべてのインデックスの再オープン（設定を反映するため）
            CloseIndexRequest closeRequest = new CloseIndexRequest("*");
            OpenIndexRequest openRequest = new OpenIndexRequest("*");
            
            restTemplate.execute(client -> {
                client.indices().close(closeRequest, RequestOptions.DEFAULT);
                return client.indices().open(openRequest, RequestOptions.DEFAULT);
            });
            
            log.info("User dictionary updated and applied successfully");
            
        } catch (Exception e) {
            throw new RuntimeException("Failed to update user dictionary", e);
        }
    }
}
```

## 9. インターフェース定義

### 9.1 IndexManager インターフェース

Spring Data Elasticsearchを活用したインデックス管理のためのインターフェースです。

```java
public interface IndexManager {
    /**
     * インデックスを作成する
     * @param resourceType リソース種別
     * @param indexVersion バージョン
     * @param settings インデックス設定
     * @param mappings マッピング定義
     * @return 作成されたインデックス名
     */
    String createIndex(String resourceType, String indexVersion, 
                     Map<String, Object> settings, Map<String, Object> mappings);
    
    /**
     * インデックスにエイリアスを設定する
     * @param indexName インデックス名
     * @param aliasName エイリアス名
     * @return 設定成功の場合true
     */
    boolean setAlias(String indexName, String aliasName);
    
    /**
     * アトミックにエイリアスを切り替える
     * @param oldIndex 古いインデックス
     * @param newIndex 新しいインデックス
     * @param aliasName エイリアス名
     * @return 切り替え成功の場合true
     */
    boolean switchAlias(String oldIndex, String newIndex, String aliasName);
    
    /**
     * インデックスの健全性をチェックする
     * @param indexNameOrAlias インデックス名またはエイリアス
     * @return 健全性チェック結果
     */
    IndexHealthStatus checkIndexHealth(String indexNameOrAlias);
    
    /**
     * インデックスを削除する
     * @param indexName インデックス名
     * @return 削除成功の場合true
     */
    boolean deleteIndex(String indexName);
    
    /**
     * インデックスを最適化する
     * @param indexName インデックス名
     * @return 最適化成功の場合true
     */
    boolean optimizeIndex(String indexName);
}
```

### 9.2 IndexSynchronizer インターフェース

```java
public interface IndexSynchronizer {
    /**
     * データの同期を開始する
     * @param resourceType リソース種別
     * @param syncMode 同期モード（FULL, INCREMENTAL）
     * @return 同期ジョブID
     */
    String startSync(String resourceType, SyncMode syncMode);
    
    /**
     * 同期ジョブのステータスを取得する
     * @param jobId 同期ジョブID
     * @return 同期ジョブステータス
     */
    SyncJobStatus getSyncStatus(String jobId);
    
    /**
     * 同期ジョブをキャンセルする
     * @param jobId 同期ジョブID
     * @return キャンセル成功の場合true
     */
    boolean cancelSync(String jobId);
    
    /**
     * 最終同期情報を取得する
     * @param resourceType リソース種別
     * @return 最終同期情報
     */
    LastSyncInfo getLastSyncInfo(String resourceType);
    
    /**
     * データ変更イベントを受け取る
     * Spring ApplicationEventリスナーとして実装
     */
    @EventListener
    void handleDataChangeEvent(DataChangeEvent event);
}
```

## 10. バッチ処理定義

### 10.1 定期同期バッチ

```java
@Configuration
@EnableScheduling
public class IndexSyncSchedulerConfig {
    
    private final IndexSynchronizer synchronizer;
    
    @Autowired
    public IndexSyncSchedulerConfig(IndexSynchronizer synchronizer) {
        this.synchronizer = synchronizer;
    }
    
    /**
     * 15分ごとにすべてのリソースタイプの増分同期を実行
     */
    @Scheduled(fixedRate = 900000) // 15分 = 900,000ミリ秒
    public void scheduledIncrementalSync() {
        List<String> resourceTypes = Arrays.asList("engineers", "projects", "contracts", "invoices");
        
        for (String resourceType : resourceTypes) {
            try {
                synchronizer.startSync(resourceType, SyncMode.INCREMENTAL);
            } catch (Exception e) {
                log.error("Failed to schedule incremental sync for {}: {}", resourceType, e.getMessage());
            }
        }
    }
}
```

### 10.2 インデックス最適化バッチ

```java
@Configuration
@EnableBatchProcessing
public class IndexOptimizationJobConfig {
    
    @Autowired
    private JobBuilderFactory jobBuilderFactory;
    
    @Autowired
    private StepBuilderFactory stepBuilderFactory;
    
    @Autowired
    private IndexManager indexManager;
    
    @Bean
    public Job indexOptimizationJob() {
        return jobBuilderFactory.get("indexOptimizationJob")
                .incrementer(new RunIdIncrementer())
                .flow(optimizeIndicesStep())
                .end()
                .build();
    }
    
    @Bean
    public Step optimizeIndicesStep() {
        return stepBuilderFactory.get("optimizeIndicesStep")
                .tasklet(new OptimizeIndicesTasklet(indexManager))
                .build();
    }
    
    public static class OptimizeIndicesTasklet implements Tasklet {
        
        private final IndexManager indexManager;
        
        public OptimizeIndicesTasklet(IndexManager indexManager) {
            this.indexManager = indexManager;
        }
        
        @Override
        public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {
            // 対象のエイリアスリスト
            List<String> aliases = Arrays.asList(
                "engineers-current", "projects-current", "contracts-current", "invoices-current");
                
            for (String alias : aliases) {
                try {
                    IndexHealthStatus status = indexManager.checkIndexHealth(alias);
                    if (status != null && !status.isRed()) {
                        indexManager.optimizeIndex(alias);
                        log.info("Successfully optimized index for alias: {}", alias);
                    } else {
                        log.warn("Skipping optimization for alias {} due to unhealthy status: {}", alias, status);
                    }
                } catch (Exception e) {
                    log.error("Failed to optimize index for alias {}: {}", alias, e.getMessage());
                }
            }
            
            return RepeatStatus.FINISHED;
        }
    }
    
    @Bean
    public Trigger indexOptimizationTrigger() {
        return TriggerBuilder.newTrigger()
                .withIdentity("indexOptimizationTrigger")
                .withSchedule(CronScheduleBuilder.dailyAtHourAndMinute(1, 0)) // 毎日午前1:00に実行
                .build();
    }
}
```

### 10.3 インデックス再構築バッチ

```java
@Configuration
@EnableBatchProcessing
public class IndexRebuildJobConfig {
    
    @Autowired
    private JobBuilderFactory jobBuilderFactory;
    
    @Autowired
    private StepBuilderFactory stepBuilderFactory;
    
    @Autowired
    private IndexRebuildService rebuildService;
    
    @Bean
    public Job indexRebuildJob() {
        return jobBuilderFactory.get("indexRebuildJob")
                .incrementer(new RunIdIncrementer())
                .flow(rebuildIndicesStep())
                .end()
                .build();
    }
    
    @Bean
    public Step rebuildIndicesStep() {
        return stepBuilderFactory.get("rebuildIndicesStep")
                .tasklet(new RebuildIndicesTasklet(rebuildService))
                .build();
    }
    
    public static class RebuildIndicesTasklet implements Tasklet {
        
        private final IndexRebuildService rebuildService;
        
        public RebuildIndicesTasklet(IndexRebuildService rebuildService) {
            this.rebuildService = rebuildService;
        }
        
        @Override
        public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {
            // バッチ実行パラメータからリソースタイプを取得（指定がなければすべて）
            JobParameters params = chunkContext.getStepContext().getStepExecution().getJobParameters();
            String resourceType = params.getString("resourceType");
            
            List<String> resourceTypes;
            if (resourceType != null && !resourceType.trim().isEmpty()) {
                resourceTypes = Collections.singletonList(resourceType);
            } else {
                resourceTypes = Arrays.asList("engineers", "projects", "contracts", "invoices");
            }
            
            // 各リソースタイプのインデックスを再構築（エラーが発生しても続行）
            List<Throwable> errors = new ArrayList<>();
            
            for (String type : resourceTypes) {
                try {
                    CompletableFuture<String> future = rebuildService.rebuildIndex(type);
                    String jobId = future.get(3, TimeUnit.HOURS); // 最大3時間待機
                    log.info("Successfully rebuilt index for resource type {} with job ID: {}", type, jobId);
                } catch (Exception e) {
                    log.error("Failed to rebuild index for resource type {}: {}", type, e.getMessage());
                    errors.add(e);
                }
            }
            
            // エラーがあった場合は例外をスロー
            if (!errors.isEmpty()) {
                throw new JobExecutionException(
                    String.format("Failed to rebuild %d of %d indices", errors.size(), resourceTypes.size()));
            }
            
            return RepeatStatus.FINISHED;
        }
    }
    
    @Bean
    public Trigger indexRebuildTrigger() {
        return TriggerBuilder.newTrigger()
                .withIdentity("indexRebuildTrigger")
                .withSchedule(CronScheduleBuilder.weeklyOnDayAndHourAndMinute(
                    DateBuilder.SUNDAY, 3, 0)) // 毎週日曜日の午前3:00に実行
                .build();
    }
}
```

## 11. 運用管理

### 11.1 インデックス管理画面

インデックス管理者向けの管理画面を提供し、以下の操作を可能にします：

```java
@Controller
@RequestMapping("/admin/search/indices")
@PreAuthorize("hasRole('ADMIN')")
public class IndexManagementController {
    
    private final IndexManager indexManager;
    private final IndexSynchronizer indexSynchronizer;
    private final IndexRebuildService rebuildService;
    
    @Autowired
    public IndexManagementController(IndexManager indexManager, 
                                  IndexSynchronizer indexSynchronizer,
                                  IndexRebuildService rebuildService) {
        this.indexManager = indexManager;
        this.indexSynchronizer = indexSynchronizer;
        this.rebuildService = rebuildService;
    }
    
    /**
     * インデックス一覧ページを表示
     */
    @GetMapping
    public String listIndices(Model model) {
        // インデックス情報の取得 ...
        return "admin/search/indices/list";
    }
    
    /**
     * 手動同期実行
     */
    @PostMapping("/sync")
    public String syncIndex(@RequestParam("resourceType") String resourceType,
                         @RequestParam("mode") String mode) {
        SyncMode syncMode = "full".equals(mode) ? SyncMode.FULL : SyncMode.INCREMENTAL;
        indexSynchronizer.startSync(resourceType, syncMode);
        return "redirect:/admin/search/indices";
    }
    
    /**
     * インデックス再構築実行
     */
    @PostMapping("/rebuild")
    public String rebuildIndex(@RequestParam("resourceType") String resourceType) {
        rebuildService.rebuildIndex(resourceType);
        return "redirect:/admin/search/indices";
    }
    
    /**
     * インデックス最適化実行
     */
    @PostMapping("/optimize")
    public String optimizeIndex(@RequestParam("indexName") String indexName) {
        indexManager.optimizeIndex(indexName);
        return "redirect:/admin/search/indices";
    }
    
    /**
     * インデックス削除
     */
    @PostMapping("/delete")
    public String deleteIndex(@RequestParam("indexName") String indexName) {
        indexManager.deleteIndex(indexName);
        return "redirect:/admin/search/indices";
    }
}
```

### 11.2 モニタリングダッシュボード

以下の項目をモニタリングするためのSpring Actuatorベースのダッシュボードを提供します：

```java
@Configuration
@EnableWebMvc
public class MonitoringConfig extends WebMvcConfigurationSupport {
    
    @Override
    public void addViewControllers(ViewControllerRegistry registry) {
        registry.addViewController("/admin/search/monitoring").setViewName("admin/search/monitoring/dashboard");
    }
    
    @Bean
    public MeterRegistryCustomizer<MeterRegistry> metricsCommonTags() {
        return registry -> registry.config().commonTags("application", "ses-manager");
    }
    
    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
    
    @Bean
    public JvmThreadMetrics threadMetrics() {
        return new JvmThreadMetrics();
    }
    
    @Bean
    public JvmMemoryMetrics memoryMetrics() {
        return new JvmMemoryMetrics();
    }
    
    @Bean
    public JvmGcMetrics gcMetrics() {
        return new JvmGcMetrics();
    }
    
    @Bean
    public SystemMetrics systemMetrics() {
        return new SystemMetrics();
    }
    
    @Bean
    public PrometheusScrapeMvcEndpoint prometheusEndpoint(CollectorRegistry collectorRegistry) {
        return new PrometheusScrapeMvcEndpoint(collectorRegistry);
    }
}
```

## 12. 拡張性設計

### 12.1 新リソース追加対応

新しい検索対象リソースを追加する際のSpring標準機能を活用したプロセス：

1. リソース用のSpring Data JDBCエンティティとリポジトリを作成
2. Spring Data Elasticsearchのインデックス設定・マッピング定義を作成 
3. ResourceDataProviderインターフェースの実装クラスをSpring Beanとして登録
4. ApplicationEventListenerで変更通知を連携

```java
@Service
@RequiredArgsConstructor
public class NewResourceTypeIndexingService {

    private final ApplicationEventPublisher eventPublisher;
    
    @EventListener
    @Transactional
    public void handleNewResourceCreate(NewResourceCreatedEvent event) {
        // 新リソース作成イベントを検索イベントに変換して発行
        DataChangeEvent searchEvent = new DataChangeEvent(
            event.getSource(),
            "new_resource_type",
            event.getResourceId().toString(),
            DataChangeType.CREATE
        );
        
        eventPublisher.publishEvent(searchEvent);
    }
    
    @EventListener
    @Transactional
    public void handleNewResourceUpdate(NewResourceUpdatedEvent event) {
        // 新リソース更新イベントを検索イベントに変換して発行
        DataChangeEvent searchEvent = new DataChangeEvent(
            event.getSource(),
            "new_resource_type",
            event.getResourceId().toString(),
            DataChangeType.UPDATE
        );
        
        eventPublisher.publishEvent(searchEvent);
    }
    
    @EventListener
    @Transactional
    public void handleNewResourceDelete(NewResourceDeletedEvent event) {
        // 新リソース削除イベントを検索イベントに変換して発行
        DataChangeEvent searchEvent = new DataChangeEvent(
            event.getSource(),
            "new_resource_type",
            event.getResourceId().toString(),
            DataChangeType.DELETE
        );
        
        eventPublisher.publishEvent(searchEvent);
    }
}
```

### 12.2 マルチテナント対応

Spring Data JDBCとSpring Data Elasticsearchを活用したマルチテナント環境での対応方法：

```java
@Configuration
public class MultiTenantElasticsearchConfig {

    @Bean
    public RestHighLevelClient elasticsearchClient() {
        // 基本設定...
        return new RestHighLevelClient(builder);
    }
    
    @Bean
    public ElasticsearchOperations elasticsearchTemplate(RestHighLevelClient client) {
        ElasticsearchConverter converter = elasticsearchConverter();
        return new ElasticsearchRestTemplate(client, converter);
    }
    
    @Bean
    public ElasticsearchCustomConversions elasticsearchCustomConversions() {
        return new ElasticsearchCustomConversions(Collections.emptyList());
    }
    
    @Bean
    public TenantIndexNameProvider tenantIndexNameProvider() {
        return new TenantIndexNameProvider();
    }
    
    public static class TenantIndexNameProvider {
        public String getIndexNameForTenant(String baseIndexName, String tenantId) {
            return tenantId + "-" + baseIndexName;
        }
    }
}
```

## 13. リソース要件

### 13.1 ストレージ要件

| リソース種別 | レコード数想定 | レコードサイズ | インデックスサイズ | 冗長化 | 合計 |
|------------|--------------|--------------|------------------|--------|-----|
| 技術者 | 10,000 | 10 KB | 100 MB | x3 | 300 MB |
| 案件 | 5,000 | 15 KB | 75 MB | x3 | 225 MB |
| 契約 | 20,000 | 8 KB | 160 MB | x3 | 480 MB |
| 合計 | - | - | - | - | 約 1.5 GB |

### 13.2 スケールアウト計画

- **初期構成**: Spring Data Elasticsearchによる3ノードクラスター
- **中期構成**: Spring Data Elasticsearchによる5ノードクラスター（レプリカシャード増加）
- **長期構成**: Spring Cloud AWS ElasticsearchServiceによるマネージドサービス利用

## 14. パフォーマンスチューニング

### 14.1 インデックス設定最適化

以下の設定パラメータをSpring Data Elasticsearchで最適化します：

```java
@Bean
public IndexSettings defaultIndexSettings() {
    return IndexSettings.builder()
        .refreshInterval("5s")
        .numberOfShards(3)
        .numberOfReplicas(1)
        .translogDurability("async")
        .translogSyncInterval("5s")
        .translogFlushThresholdSize("1gb")
        .mappingTotalFieldsLimit(1000)
        .maxResultWindow(10000)
        .build();
}
```

### 14.2 バルクインデックス最適化

Spring Data ElasticsearchのBulkOperationsを使用したバルク処理の最適化パラメータ：

```java
@Service
@RequiredArgsConstructor
public class OptimizedBulkIndexingService {

    private final ElasticsearchOperations operations;
    
    /**
     * 最適化されたバルクインデックス処理
     */
    public BulkResponse bulkIndex(String resourceType, List<Map<String, Object>> items) {
        // 最適なバッチサイズの計算
        int optimalBatchSize = calculateOptimalBatchSize(items);
        
        // バルク操作の準備
        BulkOperations bulkOps = operations.bulkOps(BulkOperations.BulkMode.INDEX, resourceType);
        
        // バッチ処理
        AtomicInteger count = new AtomicInteger(0);
        List<List<Map<String, Object>>> batches = Lists.partition(items, optimalBatchSize);
        
        for (List<Map<String, Object>> batch : batches) {
            List<IndexQuery> queries = batch.stream()
                .map(item -> IndexQuery.builder()
                    .withId(item.get("id").toString())
                    .withObject(item)
                    .build())
                .collect(Collectors.toList());
                
            bulkOps.addQueries(queries);
            count.addAndGet(batch.size());
        }
        
        // バルク操作の実行
        BulkResponse response = bulkOps.execute();
        
        log.info("Bulk indexed {} items of type {} in {} ms", 
               count.get(), resourceType, response.getTook());
               
        return response;
    }
    
    /**
     * 最適なバッチサイズを計算
     */
    private int calculateOptimalBatchSize(List<Map<String, Object>> items) {
        if (items.isEmpty()) {
            return 1000; // デフォルト
        }
        
        // アイテムの平均サイズを計算
        int sampleSize = Math.min(10, items.size());
        long totalSize = 0;
        
        for (int i = 0; i < sampleSize; i++) {
            // マップのサイズを概算
            Map<String, Object> item = items.get(i);
            long itemSize = estimateMapSize(item);
            totalSize += itemSize;
        }
        
        long avgSize = totalSize / sampleSize;
        
        // バッチサイズの計算（目標: 5-15MBのバッチサイズ）
        int targetBatchSize = (int) (10 * 1024 * 1024 / avgSize); // 10MBを目標
        
        // バッチサイズを1000-5000の範囲に制限
        return Math.max(1000, Math.min(5000, targetBatchSize));
    }
    
    /**
     * マップのサイズを概算
     */
    private long estimateMapSize(Map<String, Object> map) {
        long size = 0;
        for (Map.Entry<String, Object> entry : map.entrySet()) {
            size += entry.getKey().length() * 2; // キーのサイズ（UTF-16文字列）
            
            Object value = entry.getValue();
            if (value == null) {
                size += 4; // null参照
            } else if (value instanceof String) {
                size += ((String) value).length() * 2; // 文字列サイズ
            } else if (value instanceof Number) {
                size += 8; // 数値のサイズ
            } else if (value instanceof Boolean) {
                size += 1; // ブールのサイズ
            } else if (value instanceof Map) {
                size += estimateMapSize((Map<String, Object>) value); // 再帰的に計算
            } else if (value instanceof Collection) {
                // コレクションの大まかなサイズ
                size += 16 + ((Collection<?>) value).size() * 8;
            } else {
                size += 32; // その他のオブジェクト
            }
        }
        return size;
    }
}
```

## 15. 障害対策

### 15.1 障害シナリオと対策

| 障害シナリオ | 影響 | 対策 |
|------------|------|------|
| ノード障害 | 一部シャードの一時的な利用不可 | Spring Data Elasticsearchの冗長化設定、自動シャード再配置 |
| クラスター分断 | スプリットブレイン発生リスク | 適切なマスターノード設定、Spring Cloud Config経由での設定 |
| インデックス破損 | 検索結果の不整合 | Spring Bootによる定期的なスナップショット取得と自動復元プロセス |
| 同期遅延 | 検索結果と実データの不一致 | Spring Actuatorによる同期監視と自動リカバリプロセス |

### 15.2 バックアップ・リカバリ

```java
@Configuration
@EnableScheduling
public class ElasticsearchBackupConfig {

    private final ElasticsearchRestTemplate restTemplate;
    private final String repositoryName;
    private final String backupBasePath;
    
    @Autowired
    public ElasticsearchBackupConfig(
            ElasticsearchRestTemplate restTemplate,
            @Value("${elasticsearch.backup.repository-name:ses_backup}") String repositoryName,
            @Value("${elasticsearch.backup.base-path:/backup/elasticsearch}") String backupBasePath) {
        this.restTemplate = restTemplate;
        this.repositoryName = repositoryName;
        this.backupBasePath = backupBasePath;
    }
    
    @PostConstruct
    public void initBackupRepository() {
        try {
            // バックアップリポジトリの登録確認
            GetRepositoriesRequest getRepoRequest = new GetRepositoriesRequest(repositoryName);
            GetRepositoriesResponse getRepoResponse = restTemplate.execute(client -> 
                client.snapshot().getRepository(getRepoRequest, RequestOptions.DEFAULT));
                
            if (getRepoResponse.repositories().isEmpty()) {
                // バックアップリポジトリの作成
                PutRepositoryRequest putRepoRequest = new PutRepositoryRequest(repositoryName);
                
                Settings.Builder settings = Settings.builder()
                                         .put("type", "fs")
                                         .put("location", backupBasePath)
                                         .put("compress", true);
                                         
                putRepoRequest.settings(settings);
                
                restTemplate.execute(client -> 
                    client.snapshot().createRepository(putRepoRequest, RequestOptions.DEFAULT));
                    
                log.info("Elasticsearch backup repository created: {}", repositoryName);
            } else {
                log.info("Elasticsearch backup repository already exists: {}", repositoryName);
            }
        } catch (Exception e) {
            log.error("Failed to initialize backup repository: {}", e.getMessage(), e);
        }
    }
    
    /**
     * 日次インデックススナップショット
     */
    @Scheduled(cron = "0 0 2 * * ?") // 毎日午前2時
    public void createDailySnapshot() {
        String snapshotName = "daily-" + DateTimeFormatter.BASIC_ISO_DATE.format(LocalDate.now());
        createSnapshot(snapshotName, "日次スナップショット", false);
    }
    
    /**
     * 週次フルスナップショット
     */
    @Scheduled(cron = "0 0 3 ? * SUN") // 毎週日曜日午前3時
    public void createWeeklySnapshot() {
        String snapshotName = "weekly-" + DateTimeFormatter.ofPattern("yyyy-MM-W").format(LocalDate.now());
        createSnapshot(snapshotName, "週次フルスナップショット", true);
    }
    
    /**
     * スナップショットを作成
     */
    private void createSnapshot(String snapshotName, String description, boolean includeGlobalState) {
        try {
            // スナップショットリクエストの作成
            CreateSnapshotRequest request = new CreateSnapshotRequest(repositoryName, snapshotName);
            request.waitForCompletion(false); // 非同期実行
            
            // スナップショット設定
            request.includeGlobalState(includeGlobalState);
            request.partial(false);
            
            // スナップショットのメタデータ設定
            Map<String, Object> metadata = new HashMap<>();
            metadata.put("creation_date", System.currentTimeMillis());
            metadata.put("description", description);
            metadata.put("created_by", "ses-manager-backup-service");
            
            // インデックスのリスト指定（または全インデックス）
            request.indices("*"); // 全インデックス
            
            // スナップショットの実行
            CreateSnapshotResponse response = restTemplate.execute(client -> 
                client.snapshot().create(request, RequestOptions.DEFAULT));
                
            log.info("Elasticsearch snapshot creation started: {} (accepted: {})", 
                   snapshotName, response.getSnapshotInfo().accepted());
                   
        } catch (Exception e) {
            log.error("Failed to create snapshot {}: {}", snapshotName, e.getMessage(), e);
        }
    }
    
    /**
     * 古いスナップショットの削除
     */
    @Scheduled(cron = "0 0 4 * * ?") // 毎日午前4時
    public void cleanupOldSnapshots() {
        try {
            // 日次スナップショットの保持期間: 14日
            deleteSnapshotsOlderThan("daily-*", Period.ofDays(14));
            
            // 週次スナップショットの保持期間: 8週
            deleteSnapshotsOlderThan("weekly-*", Period.ofWeeks(8));
            
        } catch (Exception e) {
            log.error("Failed to cleanup old snapshots: {}", e.getMessage(), e);
        }
    }
    
    /**
     * 特定のパターンと日付より古いスナップショットを削除
     */
    private void deleteSnapshotsOlderThan(String pattern, Period retentionPeriod) throws Exception {
        // スナップショット一覧の取得
        GetSnapshotsRequest getRequest = new GetSnapshotsRequest(repositoryName);
        getRequest.snapshots(new String[]{pattern});
        
        GetSnapshotsResponse getResponse = restTemplate.execute(client -> 
            client.snapshot().get(getRequest, RequestOptions.DEFAULT));
            
        // 現在日時から保持期間を引いた時間よりも古いスナップショットを削除
        long cutoffTimeMillis = System.currentTimeMillis() - 
                              ChronoUnit.MILLIS.between(
                                  LocalDateTime.now().minus(retentionPeriod),
                                  LocalDateTime.now());
                                  
        List<String> snapshotsToDelete = new ArrayList<>();
        
        for (SnapshotInfo info : getResponse.getSnapshots()) {
            Map<String, Object> metadata = info.userMetadata();
            if (metadata != null && metadata.containsKey("creation_date")) {
                long creationTime = (long) metadata.get("creation_date");
                if (creationTime < cutoffTimeMillis) {
                    snapshotsToDelete.add(info.name());
                }
            }
        }
        
        // スナップショットの削除
        if (!snapshotsToDelete.isEmpty()) {
            DeleteSnapshotRequest deleteRequest = new DeleteSnapshotRequest(
                repositoryName, snapshotsToDelete.toArray(new String[0]));
                
            restTemplate.execute(client -> 
                client.snapshot().delete(deleteRequest, RequestOptions.DEFAULT));
                
            log.info("Deleted {} old snapshots: {}", snapshotsToDelete.size(), snapshotsToDelete);
        }
    }
}
```