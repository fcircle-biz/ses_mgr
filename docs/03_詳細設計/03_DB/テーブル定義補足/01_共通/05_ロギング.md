# 共通モジュール - ロギングテーブル定義補足

## 1. テーブル概要

ロギング機能は、システム全体の動作記録、監査証跡、例外情報、パフォーマンスデータなどを記録する重要な共通基盤です。このモジュールでは、様々なレベルと種類のログ情報を効率的に格納し、分析可能な形で提供します。

### 1.1 テーブル一覧

| テーブル名 | 説明 | 主要列 |
|----------|------|-------|
| `common.application_log` | アプリケーションログ | `id`, `log_level`, `logger_name`, `message`, `timestamp` |
| `common.error_log` | エラーログ | `id`, `error_code`, `error_message`, `stack_trace`, `timestamp` |
| `common.audit_log` | 監査ログ | `id`, `user_id`, `action`, `entity_type`, `entity_id`, `timestamp` |
| `common.performance_log` | パフォーマンス計測 | `id`, `operation_type`, `duration_ms`, `resource_usage`, `timestamp` |
| `common.data_change_log` | データ変更ログ | `id`, `table_name`, `record_id`, `operation_type`, `old_values`, `new_values` |
| `common.security_log` | セキュリティ関連ログ | `id`, `event_type`, `severity`, `details`, `source_ip`, `timestamp` |
| `common.integration_log` | 外部システム連携ログ | `id`, `system_name`, `operation`, `request_data`, `response_data`, `status` |

## 2. 主要テーブル詳細

### 2.1 application_log テーブル

アプリケーションの一般的なログ情報を格納するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.application_log (
    id bigserial PRIMARY KEY,
    log_level varchar(10) NOT NULL,
    logger_name varchar(255) NOT NULL,
    message text NOT NULL,
    context_data jsonb,
    thread_name varchar(100),
    class_name varchar(255),
    method_name varchar(100),
    line_number integer,
    timestamp timestamptz NOT NULL DEFAULT CURRENT_TIMESTAMP,
    session_id varchar(100),
    request_id varchar(100),
    user_id integer,
    CONSTRAINT ck_application_log_level CHECK (log_level IN ('TRACE', 'DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_application_log` | PRIMARY KEY | `id` | 主キー |
| `ix_application_log_timestamp` | B-tree | `timestamp` | 時系列検索 |
| `ix_application_log_level` | B-tree | `log_level` | ログレベルによる検索 |
| `ix_application_log_logger` | B-tree | `logger_name` | ロガー名による検索 |
| `ix_application_log_user_id` | B-tree | `user_id` | ユーザーIDによる検索 |
| `ix_application_log_request_id` | B-tree | `request_id` | リクエストIDによる検索 |

#### 特記事項

- パーティショニング必須のテーブル（日付または月単位のレンジパーティショニング推奨）
- 高頻度書き込みが発生するため、専用テーブルスペースの使用を検討
- `context_data`はJSONB型で柔軟な追加コンテキスト情報を格納
- スロークエリ対策として、頻出検索パターンに合わせたインデックス最適化が必要

### 2.2 error_log テーブル

システムで発生したエラーや例外情報を詳細に記録するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.error_log (
    id bigserial PRIMARY KEY,
    error_code varchar(50),
    error_type varchar(255) NOT NULL,
    error_message text NOT NULL,
    stack_trace text,
    root_cause text,
    severity varchar(20) NOT NULL,
    is_handled boolean NOT NULL DEFAULT false,
    source_location varchar(255),
    context_data jsonb,
    timestamp timestamptz NOT NULL DEFAULT CURRENT_TIMESTAMP,
    request_id varchar(100),
    session_id varchar(100),
    user_id integer,
    request_data text,
    server_name varchar(100),
    environment varchar(20) NOT NULL,
    CONSTRAINT ck_error_log_severity CHECK (severity IN ('LOW', 'MEDIUM', 'HIGH', 'CRITICAL')),
    CONSTRAINT ck_error_log_environment CHECK (environment IN ('DEV', 'TEST', 'STAGING', 'PROD'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_error_log` | PRIMARY KEY | `id` | 主キー |
| `ix_error_log_timestamp` | B-tree | `timestamp` | 時系列検索 |
| `ix_error_log_error_code` | B-tree | `error_code` | エラーコードによる検索 |
| `ix_error_log_error_type` | B-tree | `error_type` | エラータイプによる検索 |
| `ix_error_log_severity` | B-tree | `severity` | 重要度による検索 |
| `ix_error_log_user_id` | B-tree | `user_id` | ユーザーIDによる検索 |
| `ix_error_log_handled` | B-tree | `is_handled` | 処理済みフラグによる検索 |

#### 特記事項

- スタックトレースは完全な例外情報を保持するため、テキスト型で格納
- エラーコードは社内で標準化されたエラーコード体系を使用
- 定期的なエラー分析のための集計クエリを最適化
- 環境ごとのエラー傾向を把握するための分析が容易な設計

### 2.3 audit_log テーブル

システム内の重要な操作や変更に関する監査証跡を記録するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.audit_log (
    id bigserial PRIMARY KEY,
    user_id integer,
    username varchar(100),
    action varchar(50) NOT NULL,
    entity_type varchar(100) NOT NULL,
    entity_id varchar(100),
    details jsonb,
    status varchar(20) NOT NULL,
    ip_address inet,
    user_agent text,
    timestamp timestamptz NOT NULL DEFAULT CURRENT_TIMESTAMP,
    request_id varchar(100),
    session_id varchar(100),
    application_module varchar(100),
    correlation_id varchar(100),
    CONSTRAINT ck_audit_log_action CHECK (action IN ('CREATE', 'READ', 'UPDATE', 'DELETE', 'LOGIN', 'LOGOUT', 'EXPORT', 'IMPORT', 'APPROVE', 'REJECT', 'SUBMIT')),
    CONSTRAINT ck_audit_log_status CHECK (status IN ('SUCCESS', 'FAILURE', 'WARNING', 'DENIED'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_audit_log` | PRIMARY KEY | `id` | 主キー |
| `ix_audit_log_timestamp` | B-tree | `timestamp` | 時系列検索 |
| `ix_audit_log_user_id` | B-tree | `user_id` | ユーザーIDによる検索 |
| `ix_audit_log_action` | B-tree | `action` | アクション種別による検索 |
| `ix_audit_log_entity_type` | B-tree | `entity_type` | エンティティタイプによる検索 |
| `ix_audit_log_entity_id` | B-tree | `entity_type`, `entity_id` | エンティティ特定による検索 |
| `ix_audit_log_status` | B-tree | `status` | ステータスによる検索 |
| `ix_audit_log_ip_address` | B-tree | `ip_address` | IPアドレスによる検索 |

#### 特記事項

- 監査目的で長期保存が必要なため、アーカイブ戦略を慎重に設計
- ユーザー削除後もログを追跡できるよう、ユーザー名を冗長に保存
- 詳細情報はJSONB形式で柔軟に格納
- 法令遵守や内部監査に対応した検索機能の最適化

### 2.4 performance_log テーブル

システムのパフォーマンスメトリクスを記録するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.performance_log (
    id bigserial PRIMARY KEY,
    operation_type varchar(100) NOT NULL,
    operation_name varchar(255) NOT NULL,
    start_time timestamptz NOT NULL,
    end_time timestamptz NOT NULL,
    duration_ms integer NOT NULL,
    cpu_usage real,
    memory_usage real,
    db_calls integer,
    io_operations integer,
    result_size integer,
    thread_name varchar(100),
    resource_name varchar(100),
    request_id varchar(100),
    session_id varchar(100),
    user_id integer,
    details jsonb,
    environment varchar(20) NOT NULL,
    CONSTRAINT ck_performance_log_operation_type CHECK (operation_type IN ('HTTP_REQUEST', 'DB_QUERY', 'SERVICE_CALL', 'BATCH_JOB', 'INTEGRATION_CALL', 'CACHE_OPERATION', 'FILE_OPERATION'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_performance_log` | PRIMARY KEY | `id` | 主キー |
| `ix_performance_log_start_time` | B-tree | `start_time` | 開始時間による検索 |
| `ix_performance_log_operation_type` | B-tree | `operation_type` | 操作タイプによる検索 |
| `ix_performance_log_operation_name` | B-tree | `operation_name` | 操作名による検索 |
| `ix_performance_log_duration` | B-tree | `duration_ms` | 処理時間による検索 |
| `ix_performance_log_resource` | B-tree | `resource_name` | リソース名による検索 |

#### 特記事項

- パフォーマンス分析用の集計クエリを効率化するインデックス設計
- 長期傾向分析のためのサマリテーブルへの自動集計処理を実装
- リソース使用率の閾値超過検出のためのアラート機能と連携
- 大量データのため、早期のパーティショニングと古いデータのアーカイブが必要

### 2.5 data_change_log テーブル

重要データの変更履歴を追跡するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.data_change_log (
    id bigserial PRIMARY KEY,
    table_name varchar(100) NOT NULL,
    record_id varchar(100) NOT NULL,
    operation_type varchar(10) NOT NULL,
    old_values jsonb,
    new_values jsonb,
    changed_columns text[],
    timestamp timestamptz NOT NULL DEFAULT CURRENT_TIMESTAMP,
    user_id integer,
    username varchar(100),
    application_name varchar(100),
    transaction_id varchar(100),
    ip_address inet,
    CONSTRAINT ck_data_change_log_operation_type CHECK (operation_type IN ('INSERT', 'UPDATE', 'DELETE', 'TRUNCATE'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_data_change_log` | PRIMARY KEY | `id` | 主キー |
| `ix_data_change_log_timestamp` | B-tree | `timestamp` | 時系列検索 |
| `ix_data_change_log_table_record` | B-tree | `table_name`, `record_id` | テーブルとレコードによる検索 |
| `ix_data_change_log_operation` | B-tree | `operation_type` | 操作タイプによる検索 |
| `ix_data_change_log_user_id` | B-tree | `user_id` | ユーザーIDによる検索 |
| `gin_data_change_log_changed_columns` | GIN | `changed_columns` | 変更列による検索 |

#### 特記事項

- 変更前後の値をJSON形式で保存し、差分比較を容易に
- 重要な業務テーブルのみを対象とし、データ量の肥大化を防止
- 個人情報などの機密データはマスキングして保存
- 長期保存とパフォーマンスのバランスを考慮したアーカイブ戦略

### 2.6 security_log テーブル

セキュリティ関連イベントを記録するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.security_log (
    id bigserial PRIMARY KEY,
    event_type varchar(50) NOT NULL,
    severity varchar(20) NOT NULL,
    details text NOT NULL,
    source_ip inet,
    user_agent text,
    user_id integer,
    username varchar(100),
    target_resource varchar(255),
    action_result varchar(20) NOT NULL,
    timestamp timestamptz NOT NULL DEFAULT CURRENT_TIMESTAMP,
    session_id varchar(100),
    request_id varchar(100),
    threat_level varchar(20),
    follow_up_action varchar(50),
    CONSTRAINT ck_security_log_event_type CHECK (event_type IN ('AUTHENTICATION_FAILURE', 'AUTHORIZATION_FAILURE', 'PASSWORD_CHANGE', 'ACCOUNT_LOCKOUT', 'SUSPICIOUS_ACTIVITY', 'PERMISSION_CHANGE', 'DATA_ACCESS_VIOLATION')),
    CONSTRAINT ck_security_log_severity CHECK (severity IN ('INFO', 'WARNING', 'MEDIUM', 'HIGH', 'CRITICAL')),
    CONSTRAINT ck_security_log_action_result CHECK (action_result IN ('SUCCESS', 'FAILURE', 'BLOCKED', 'ALLOWED', 'DEFERRED'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_security_log` | PRIMARY KEY | `id` | 主キー |
| `ix_security_log_timestamp` | B-tree | `timestamp` | 時系列検索 |
| `ix_security_log_event_type` | B-tree | `event_type` | イベント種別による検索 |
| `ix_security_log_severity` | B-tree | `severity` | 重要度による検索 |
| `ix_security_log_user_id` | B-tree | `user_id` | ユーザーIDによる検索 |
| `ix_security_log_source_ip` | B-tree | `source_ip` | IPアドレスによる検索 |
| `ix_security_log_action_result` | B-tree | `action_result` | 結果による検索 |

#### 特記事項

- セキュリティ監視システムと連携するための効率的なクエリ最適化
- 不正アクセスパターン検出のための分析機能との連携
- IPアドレスによる異常アクセス追跡のための設計
- 機密性の高いログのため、アクセス制御を厳格に管理

### 2.7 integration_log テーブル

外部システムとの連携状況を記録するテーブル。

#### テーブル定義

```sql
CREATE TABLE common.integration_log (
    id bigserial PRIMARY KEY,
    system_name varchar(100) NOT NULL,
    direction varchar(10) NOT NULL,
    operation varchar(100) NOT NULL,
    endpoint varchar(255),
    request_data text,
    response_data text,
    status varchar(20) NOT NULL,
    status_code varchar(20),
    error_message text,
    start_time timestamptz NOT NULL,
    end_time timestamptz,
    duration_ms integer,
    correlation_id varchar(100),
    user_id integer,
    request_id varchar(100),
    request_headers jsonb,
    response_headers jsonb,
    retry_count integer DEFAULT 0,
    CONSTRAINT ck_integration_log_direction CHECK (direction IN ('INBOUND', 'OUTBOUND')),
    CONSTRAINT ck_integration_log_status CHECK (status IN ('SUCCESS', 'FAILURE', 'TIMEOUT', 'RETRY', 'PENDING'))
);
```

#### インデックス設計

| インデックス名 | タイプ | 対象列 | 目的 |
|--------------|-------|-------|------|
| `pk_integration_log` | PRIMARY KEY | `id` | 主キー |
| `ix_integration_log_start_time` | B-tree | `start_time` | 開始時間による検索 |
| `ix_integration_log_system` | B-tree | `system_name` | システム名による検索 |
| `ix_integration_log_operation` | B-tree | `operation` | 操作名による検索 |
| `ix_integration_log_status` | B-tree | `status` | ステータスによる検索 |
| `ix_integration_log_correlation` | B-tree | `correlation_id` | 相関IDによる検索 |

#### 特記事項

- 外部システム連携の障害調査に必要な詳細情報を格納
- センシティブなデータはマスキングまたは暗号化して保存
- リクエスト・レスポンスデータは圧縮を検討
- 効率的なトラブルシューティングのためのクエリ最適化

## 3. クエリパターンと最適化

### 3.1 ログ検索パターン

#### 3.1.1 時間範囲とフィルタ条件を組み合わせた検索

```sql
-- 特定期間内のエラーログを重要度順に検索
SELECT
    id,
    error_code,
    error_message,
    severity,
    timestamp,
    user_id,
    request_id
FROM common.error_log
WHERE timestamp BETWEEN $1 AND $2
AND severity IN ('HIGH', 'CRITICAL')
AND environment = 'PROD'
ORDER BY 
    CASE severity
        WHEN 'CRITICAL' THEN 1
        WHEN 'HIGH' THEN 2
        ELSE 3
    END,
    timestamp DESC
LIMIT 100;

-- ユーザーIDと操作タイプによる監査ログの検索
SELECT
    id,
    action,
    entity_type,
    entity_id,
    details,
    status,
    timestamp
FROM common.audit_log
WHERE user_id = $1
AND action IN ('UPDATE', 'DELETE')
AND entity_type = $2
AND timestamp > CURRENT_TIMESTAMP - interval '30 days'
ORDER BY timestamp DESC;
```

#### 3.1.2 相関検索（リクエストIDによる追跡）

```sql
-- リクエストIDによる一連のログ追跡
WITH request_logs AS (
    -- アプリケーションログ
    SELECT
        'APPLICATION' AS log_type,
        id,
        timestamp,
        log_level AS severity,
        message AS details,
        NULL::jsonb AS data
    FROM common.application_log
    WHERE request_id = $1
    
    UNION ALL
    
    -- エラーログ
    SELECT
        'ERROR' AS log_type,
        id,
        timestamp,
        severity,
        error_message AS details,
        jsonb_build_object('error_code', error_code, 'stack_trace', stack_trace) AS data
    FROM common.error_log
    WHERE request_id = $1
    
    UNION ALL
    
    -- 監査ログ
    SELECT
        'AUDIT' AS log_type,
        id,
        timestamp,
        status AS severity,
        action || ' ' || entity_type || '/' || entity_id AS details,
        details AS data
    FROM common.audit_log
    WHERE request_id = $1
    
    UNION ALL
    
    -- パフォーマンスログ
    SELECT
        'PERFORMANCE' AS log_type,
        id,
        start_time AS timestamp,
        CASE 
            WHEN duration_ms > 1000 THEN 'HIGH'
            WHEN duration_ms > 500 THEN 'MEDIUM'
            ELSE 'LOW'
        END AS severity,
        operation_type || ' ' || operation_name AS details,
        jsonb_build_object('duration_ms', duration_ms, 'resource_name', resource_name) AS data
    FROM common.performance_log
    WHERE request_id = $1
)
SELECT *
FROM request_logs
ORDER BY timestamp;
```

### 3.2 集計クエリパターン

#### 3.2.1.エラー傾向分析

```sql
-- 時間帯別のエラー発生数
SELECT
    date_trunc('hour', timestamp) AS hour,
    error_type,
    severity,
    COUNT(*) AS error_count
FROM common.error_log
WHERE timestamp > CURRENT_TIMESTAMP - interval '7 days'
AND environment = 'PROD'
GROUP BY hour, error_type, severity
ORDER BY hour, error_count DESC;

-- 最も頻発するエラーのランキング
SELECT
    error_code,
    error_type,
    COUNT(*) AS error_count,
    MIN(timestamp) AS first_occurrence,
    MAX(timestamp) AS last_occurrence
FROM common.error_log
WHERE timestamp > CURRENT_TIMESTAMP - interval '7 days'
AND environment = 'PROD'
GROUP BY error_code, error_type
ORDER BY error_count DESC
LIMIT 20;
```

#### 3.2.2 パフォーマンス分析

```sql
-- 最も遅い操作TOP 10
SELECT
    operation_type,
    operation_name,
    COUNT(*) AS call_count,
    AVG(duration_ms) AS avg_duration,
    MAX(duration_ms) AS max_duration,
    MIN(duration_ms) AS min_duration,
    percentile_cont(0.95) WITHIN GROUP (ORDER BY duration_ms) AS p95_duration
FROM common.performance_log
WHERE start_time > CURRENT_TIMESTAMP - interval '1 day'
AND environment = 'PROD'
GROUP BY operation_type, operation_name
HAVING COUNT(*) > 10
ORDER BY avg_duration DESC
LIMIT 10;

-- 時間帯別のレスポンスタイム推移
SELECT
    date_trunc('hour', start_time) AS hour,
    operation_type,
    COUNT(*) AS call_count,
    AVG(duration_ms) AS avg_duration,
    MAX(duration_ms) AS max_duration
FROM common.performance_log
WHERE start_time > CURRENT_TIMESTAMP - interval '3 days'
AND operation_type = 'HTTP_REQUEST'
AND environment = 'PROD'
GROUP BY hour, operation_type
ORDER BY hour;
```

#### 3.2.3 セキュリティ分析

```sql
-- IPアドレス別の認証失敗回数
SELECT
    source_ip,
    COUNT(*) AS failure_count,
    MIN(timestamp) AS first_attempt,
    MAX(timestamp) AS last_attempt,
    array_agg(DISTINCT username) AS attempted_usernames
FROM common.security_log
WHERE event_type = 'AUTHENTICATION_FAILURE'
AND timestamp > CURRENT_TIMESTAMP - interval '24 hours'
GROUP BY source_ip
HAVING COUNT(*) > 5
ORDER BY failure_count DESC;

-- ユーザー別の疑わしい操作
SELECT
    user_id,
    username,
    event_type,
    COUNT(*) AS event_count
FROM common.security_log
WHERE severity IN ('HIGH', 'CRITICAL')
AND timestamp > CURRENT_TIMESTAMP - interval '7 days'
GROUP BY user_id, username, event_type
ORDER BY event_count DESC;
```

## 4. データメンテナンス

### 4.1 パーティショニングと保持ポリシー

#### 4.1.1 月次パーティション作成

```sql
-- application_logの月次パーティション作成関数
CREATE OR REPLACE FUNCTION common.create_log_partition_for_month(
    p_table_name text,
    p_schema_name text DEFAULT 'common'
)
RETURNS void AS $$
DECLARE
    next_month date;
    partition_name text;
    partition_start date;
    partition_end date;
    full_table_name text;
BEGIN
    -- 2ヶ月先の月を計算
    next_month := date_trunc('month', current_date + interval '2 month');
    
    -- 完全なテーブル名の構築
    full_table_name := p_schema_name || '.' || p_table_name;
    
    -- パーティション名の生成
    partition_name := p_table_name || '_y' || to_char(next_month, 'YYYY') || 'm' || to_char(next_month, 'MM');
    
    -- パーティション範囲の計算
    partition_start := next_month;
    partition_end := next_month + interval '1 month';
    
    -- パーティションが存在しないか確認
    IF NOT EXISTS (
        SELECT 1 FROM pg_class c
        JOIN pg_namespace n ON n.oid = c.relnamespace
        WHERE n.nspname = p_schema_name AND c.relname = partition_name
    ) THEN
        -- 対象の列名はテーブルによって異なる（timestamp または start_time）
        IF p_table_name IN ('performance_log', 'integration_log') THEN
            -- パーティション作成（start_time列使用）
            EXECUTE format(
                'CREATE TABLE %I.%I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
                p_schema_name, partition_name, full_table_name, partition_start, partition_end
            );
            
            -- インデックス作成例
            EXECUTE format(
                'CREATE INDEX ix_%I_start_time ON %I.%I (start_time)',
                partition_name, p_schema_name, partition_name
            );
        ELSE
            -- パーティション作成（timestamp列使用）
            EXECUTE format(
                'CREATE TABLE %I.%I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
                p_schema_name, partition_name, full_table_name, partition_start, partition_end
            );
            
            -- インデックス作成例
            EXECUTE format(
                'CREATE INDEX ix_%I_timestamp ON %I.%I (timestamp)',
                partition_name, p_schema_name, partition_name
            );
        END IF;
        
        RAISE NOTICE 'Created partition: %I.%I', p_schema_name, partition_name;
    END IF;
END;
$$ LANGUAGE plpgsql;

-- 毎月1日に実行（pg_cron拡張を使用）
SELECT cron.schedule('0 0 1 * *', $$
    SELECT common.create_log_partition_for_month('application_log');
    SELECT common.create_log_partition_for_month('error_log');
    SELECT common.create_log_partition_for_month('audit_log');
    SELECT common.create_log_partition_for_month('performance_log');
    SELECT common.create_log_partition_for_month('data_change_log');
    SELECT common.create_log_partition_for_month('security_log');
    SELECT common.create_log_partition_for_month('integration_log');
$$);
```

#### 4.1.2 古いデータのアーカイブまたは削除

```sql
-- 古いログデータのアーカイブ処理
CREATE OR REPLACE FUNCTION common.archive_old_log_partitions(
    p_table_name text,
    p_schema_name text DEFAULT 'common',
    p_months_to_keep integer DEFAULT 3
)
RETURNS void AS $$
DECLARE
    v_cutoff_date date;
    v_partition_name text;
    v_partition record;
BEGIN
    -- アーカイブ/削除基準日の計算
    v_cutoff_date := date_trunc('month', current_date - (p_months_to_keep || ' months')::interval);
    
    -- 対象パーティションの検索
    FOR v_partition IN
        SELECT 
            c.relname AS partition_name
        FROM pg_class c
        JOIN pg_namespace n ON n.oid = c.relnamespace
        JOIN pg_inherits i ON i.inhrelid = c.oid
        JOIN pg_class parent ON i.inhparent = parent.oid
        JOIN pg_namespace parent_ns ON parent.relnamespace = parent_ns.oid
        WHERE parent_ns.nspname = p_schema_name
        AND parent.relname = p_table_name
        AND c.relname ~ (p_table_name || '_y[0-9]{4}m[0-9]{2}')
        AND substring(c.relname from '_y([0-9]{4})m([0-9]{2})$') < to_char(v_cutoff_date, 'YYYYmm')
    LOOP
        v_partition_name := v_partition.partition_name;
        
        -- アーカイブテーブルに移動（実際の環境に合わせて調整）
        -- 注: このサンプルでは単純にテーブルを削除していますが、
        -- 実際のプロジェクトではアーカイブストレージへの退避が必要です
        
        -- 例: S3にCSVとしてエクスポート後に削除
        -- AWS拡張のaws_s3.table_to_s3関数などを使用
        
        -- 以下は単純な削除例
        EXECUTE format(
            'DROP TABLE IF EXISTS %I.%I',
            p_schema_name, v_partition_name
        );
        
        RAISE NOTICE 'Archived and dropped partition: %I.%I', p_schema_name, v_partition_name;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- 毎月15日に実行（pg_cron拡張を使用）
SELECT cron.schedule('0 0 15 * *', $$
    -- 各種ログの保持期間設定
    SELECT common.archive_old_log_partitions('application_log', 'common', 3);  -- 3ヶ月保持
    SELECT common.archive_old_log_partitions('error_log', 'common', 6);        -- 6ヶ月保持
    SELECT common.archive_old_log_partitions('audit_log', 'common', 24);       -- 24ヶ月保持（法的要件）
    SELECT common.archive_old_log_partitions('performance_log', 'common', 2);  -- 2ヶ月保持
    SELECT common.archive_old_log_partitions('data_change_log', 'common', 12); -- 12ヶ月保持
    SELECT common.archive_old_log_partitions('security_log', 'common', 12);    -- 12ヶ月保持
    SELECT common.archive_old_log_partitions('integration_log', 'common', 3);  -- 3ヶ月保持
$$);
```

### 4.2 ログローテーションとバキューム

```sql
-- 月次のバキュームと統計更新をスケジュール
SELECT cron.schedule('0 2 1 * *', $$
    -- 現在アクティブなログパーティションのVACUUM ANALYZE
    DO $$
    DECLARE
        v_current_month text := to_char(current_date, 'YYYYmm');
        v_prev_month text := to_char(current_date - interval '1 month', 'YYYYmm');
        v_log_tables text[] := ARRAY['application_log', 'error_log', 'audit_log', 'performance_log', 'data_change_log', 'security_log', 'integration_log'];
        v_table text;
        v_current_partition text;
        v_prev_partition text;
    BEGIN
        FOREACH v_table IN ARRAY v_log_tables
        LOOP
            v_current_partition := 'common.' || v_table || '_y' || substring(v_current_month, 1, 4) || 'm' || substring(v_current_month, 5, 2);
            v_prev_partition := 'common.' || v_table || '_y' || substring(v_prev_month, 1, 4) || 'm' || substring(v_prev_month, 5, 2);
            
            -- 現在月のパーティション
            EXECUTE 'VACUUM ANALYZE ' || v_current_partition;
            
            -- 前月のパーティション
            EXECUTE 'VACUUM ANALYZE ' || v_prev_partition;
        END LOOP;
    END $$;
$$);
```

### 4.3 サマリーテーブルのメンテナンス

```sql
-- エラーログサマリーテーブル定義
CREATE TABLE IF NOT EXISTS common.error_log_summary (
    id serial PRIMARY KEY,
    summary_date date NOT NULL,
    error_code varchar(50),
    error_type varchar(255) NOT NULL,
    severity varchar(20) NOT NULL,
    environment varchar(20) NOT NULL,
    error_count integer NOT NULL,
    affected_users integer NOT NULL,
    first_occurrence timestamptz NOT NULL,
    last_occurrence timestamptz NOT NULL,
    CONSTRAINT uq_error_log_summary UNIQUE (summary_date, error_code, error_type, severity, environment)
);

-- 日次サマリーの生成関数
CREATE OR REPLACE FUNCTION common.generate_error_summary(
    p_date date DEFAULT CURRENT_DATE - interval '1 day'
)
RETURNS void AS $$
BEGIN
    -- サマリーデータを生成して挿入
    INSERT INTO common.error_log_summary
    (summary_date, error_code, error_type, severity, environment, error_count, affected_users, first_occurrence, last_occurrence)
    SELECT
        p_date AS summary_date,
        error_code,
        error_type,
        severity,
        environment,
        COUNT(*) AS error_count,
        COUNT(DISTINCT user_id) AS affected_users,
        MIN(timestamp) AS first_occurrence,
        MAX(timestamp) AS last_occurrence
    FROM common.error_log
    WHERE timestamp >= p_date
    AND timestamp < p_date + interval '1 day'
    GROUP BY error_code, error_type, severity, environment
    ON CONFLICT (summary_date, error_code, error_type, severity, environment)
    DO UPDATE SET
        error_count = EXCLUDED.error_count,
        affected_users = EXCLUDED.affected_users,
        first_occurrence = EXCLUDED.first_occurrence,
        last_occurrence = EXCLUDED.last_occurrence;
    
    RAISE NOTICE 'Generated error summary for date: %', p_date;
END;
$$ LANGUAGE plpgsql;

-- 日次サマリー生成をスケジュール（毎日1:00 AMに実行）
SELECT cron.schedule('0 1 * * *', $$
    SELECT common.generate_error_summary(CURRENT_DATE - interval '1 day');
$$);
```

## 5. パフォーマンス最適化

### 5.1 インデックス最適化

#### 5.1.1 部分インデックス

```sql
-- 重要なエラーログのみのインデックス
CREATE INDEX ix_error_log_critical ON common.error_log (timestamp)
WHERE severity IN ('HIGH', 'CRITICAL');

-- 未処理の例外に特化したインデックス
CREATE INDEX ix_error_log_unhandled ON common.error_log (error_code, timestamp)
WHERE is_handled = false;

-- 最近のログに特化したインデックス（クエリが主に直近のデータにアクセスする場合）
CREATE INDEX ix_application_log_recent ON common.application_log (logger_name, log_level, timestamp)
WHERE timestamp > CURRENT_TIMESTAMP - interval '7 days';
```

#### 5.1.2 複合インデックス

```sql
-- よく使われる検索条件の組み合わせに対応する複合インデックス
CREATE INDEX ix_audit_log_user_action_time ON common.audit_log (user_id, action, entity_type, timestamp);

-- パフォーマンス分析用の複合インデックス
CREATE INDEX ix_performance_log_op_duration ON common.performance_log (operation_type, operation_name, duration_ms, start_time);

-- セキュリティ分析用の複合インデックス
CREATE INDEX ix_security_log_event_severity ON common.security_log (event_type, severity, timestamp, source_ip);
```

### 5.2 集計クエリ最適化

```sql
-- マテリアライズドビューを使用した頻出集計の高速化
-- 日次エラーカウントの集計
CREATE MATERIALIZED VIEW common.mv_daily_error_count AS
SELECT
    date_trunc('day', timestamp)::date AS error_date,
    error_type,
    severity,
    environment,
    COUNT(*) AS error_count
FROM common.error_log
WHERE timestamp > CURRENT_TIMESTAMP - interval '90 days'
GROUP BY error_date, error_type, severity, environment;

CREATE UNIQUE INDEX idx_mv_daily_error_count ON common.mv_daily_error_count (error_date, error_type, severity, environment);

-- 定期的な更新をスケジュール
SELECT cron.schedule('0 3 * * *', $$
    REFRESH MATERIALIZED VIEW CONCURRENTLY common.mv_daily_error_count;
$$);
```

### 5.3 テーブルクラスタリング

テーブルを特定の列で物理的にクラスタリングすることで、日付範囲検索などのパフォーマンスを向上させます。

```sql
-- タイムスタンプでクラスタリングするための関数
CREATE OR REPLACE FUNCTION common.cluster_log_partitions()
RETURNS void AS $$
DECLARE
    v_current_month text := to_char(current_date, 'YYYYmm');
    v_prev_month text := to_char(current_date - interval '1 month', 'YYYYmm');
    v_log_tables text[] := ARRAY['application_log', 'error_log', 'audit_log', 'data_change_log', 'security_log'];
    v_perf_tables text[] := ARRAY['performance_log', 'integration_log'];
    v_table text;
    v_partition text;
    v_index text;
BEGIN
    -- タイムスタンプでクラスタリングするテーブル
    FOREACH v_table IN ARRAY v_log_tables
    LOOP
        -- 前月のパーティションをクラスタリング
        v_partition := 'common.' || v_table || '_y' || substring(v_prev_month, 1, 4) || 'm' || substring(v_prev_month, 5, 2);
        v_index := 'ix_' || v_table || '_y' || substring(v_prev_month, 1, 4) || 'm' || substring(v_prev_month, 5, 2) || '_timestamp';
        
        EXECUTE 'CLUSTER ' || v_partition || ' USING ' || v_index;
        RAISE NOTICE 'Clustered table % using index %', v_partition, v_index;
    END LOOP;
    
    -- start_timeでクラスタリングするテーブル
    FOREACH v_table IN ARRAY v_perf_tables
    LOOP
        -- 前月のパーティションをクラスタリング
        v_partition := 'common.' || v_table || '_y' || substring(v_prev_month, 1, 4) || 'm' || substring(v_prev_month, 5, 2);
        v_index := 'ix_' || v_table || '_y' || substring(v_prev_month, 1, 4) || 'm' || substring(v_prev_month, 5, 2) || '_start_time';
        
        EXECUTE 'CLUSTER ' || v_partition || ' USING ' || v_index;
        RAISE NOTICE 'Clustered table % using index %', v_partition, v_index;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- 毎月10日に前月のパーティションをクラスタリング
SELECT cron.schedule('0 3 10 * *', $$
    SELECT common.cluster_log_partitions();
$$);
```

## 6. セキュリティ考慮事項

### 6.1 センシティブデータの保護

ログにはセンシティブな情報が含まれる可能性があります。以下の方針で対応します。

1. **自動マスキング機能**: パスワードやトークンなどの機密情報を自動的にマスキングするトリガーやルールを実装

```sql
-- データマスキングのための関数
CREATE OR REPLACE FUNCTION common.mask_sensitive_data()
RETURNS trigger AS $$
DECLARE
    v_json jsonb;
    v_masked jsonb;
BEGIN
    -- リクエストデータのマスキング
    IF TG_TABLE_NAME = 'error_log' AND NEW.request_data IS NOT NULL THEN
        BEGIN
            -- JSONとして解析を試みる
            v_json := NEW.request_data::jsonb;
            -- パスワードフィールドをマスク
            IF v_json ? 'password' THEN
                v_masked := jsonb_set(v_json, '{password}', '"*****"');
            END IF;
            -- クレジットカード番号をマスク
            IF v_json ? 'creditCard' OR v_json ? 'credit_card' THEN
                IF v_json ? 'creditCard' THEN
                    v_masked := jsonb_set(COALESCE(v_masked, v_json), '{creditCard}', '"xxxx-xxxx-xxxx-xxxx"');
                ELSE
                    v_masked := jsonb_set(COALESCE(v_masked, v_json), '{credit_card}', '"xxxx-xxxx-xxxx-xxxx"');
                END IF;
            END IF;
            
            IF v_masked IS NOT NULL THEN
                NEW.request_data := v_masked::text;
            END IF;
        EXCEPTION
            WHEN others THEN
                -- JSON解析に失敗した場合はテキスト置換を行う
                NEW.request_data := regexp_replace(NEW.request_data, '"password"\s*:\s*"[^"]*"', '"password":"*****"', 'g');
                NEW.request_data := regexp_replace(NEW.request_data, '"creditCard"\s*:\s*"[^"]*"', '"creditCard":"xxxx-xxxx-xxxx-xxxx"', 'g');
        END;
    END IF;
    
    -- その他のテーブルにも同様のマスキングを適用...
    
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- エラーログへのトリガー適用
CREATE TRIGGER tr_error_log_mask_data
BEFORE INSERT ON common.error_log
FOR EACH ROW EXECUTE FUNCTION common.mask_sensitive_data();
```

2. **アクセス制限**: ログテーブルへのアクセスは必要最小限の権限を持つロールに制限

```sql
-- ログテーブルのアクセス権限設定
REVOKE ALL ON common.application_log FROM PUBLIC;
REVOKE ALL ON common.error_log FROM PUBLIC;
REVOKE ALL ON common.audit_log FROM PUBLIC;
REVOKE ALL ON common.security_log FROM PUBLIC;
REVOKE ALL ON common.data_change_log FROM PUBLIC;

-- 基本的なログ閲覧ロール（読み取り専用）
CREATE ROLE log_viewer;
GRANT SELECT ON common.application_log TO log_viewer;
GRANT SELECT ON common.error_log TO log_viewer;

-- 監査ログ閲覧ロール（内部監査担当者用）
CREATE ROLE audit_viewer;
GRANT SELECT ON common.audit_log TO audit_viewer;
GRANT SELECT ON common.security_log TO audit_viewer;
GRANT SELECT ON common.data_change_log TO audit_viewer;

-- セキュリティ管理者ロール
CREATE ROLE security_admin;
GRANT SELECT, INSERT, UPDATE ON common.security_log TO security_admin;
```

### 6.2 アクセス監査

ログテーブル自体へのアクセスも監査の対象とします。

```sql
-- ログテーブルへのアクセス監査トリガー
CREATE OR REPLACE FUNCTION common.log_table_access_audit()
RETURNS event_trigger AS $$
DECLARE
    v_object record;
    v_audit_tables text[] := ARRAY['application_log', 'error_log', 'audit_log', 'performance_log', 'data_change_log', 'security_log', 'integration_log'];
    v_table_name text;
BEGIN
    -- アクセスされたオブジェクトの情報を取得
    FOR v_object IN SELECT * FROM pg_event_trigger_dropped_objects()
    LOOP
        IF v_object.object_type = 'table' THEN
            v_table_name := split_part(v_object.object_identity, '.', 2);
            
            IF v_table_name = ANY(v_audit_tables) THEN
                -- 監査ログテーブルへのアクセスを記録
                INSERT INTO common.meta_audit_log (
                    user_name,
                    event_type,
                    object_type,
                    object_name,
                    sql_command,
                    timestamp
                ) VALUES (
                    current_user,
                    'DROP',
                    v_object.object_type,
                    v_object.object_identity,
                    current_query(),
                    CURRENT_TIMESTAMP
                );
            END IF;
        END IF;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

-- イベントトリガーを作成
CREATE EVENT TRIGGER tr_log_table_drop_audit
ON sql_drop
EXECUTE FUNCTION common.log_table_access_audit();
```

## 7. 運用時の注意点

1. **パーティショニング戦略**: ログテーブルは成長が速いため、適切なパーティショニング戦略が重要です。月次パーティショニングとアーカイブのバランスを定期的に見直してください。

2. **ディスク使用量の監視**: ログデータは急速に増加する可能性があります。ディスク使用量を定期的に監視し、アラート閾値を設定してください。

3. **クエリパフォーマンス監視**: 複雑なログ分析クエリはリソースを消費します。実行計画の確認や低負荷時間帯での実行を検討してください。

4. **アーカイブと長期保存**: 法的要件に基づく長期保存が必要なログ（監査ログなど）は、コスト効率の高いアーカイブソリューションに移行することを検討してください。

5. **セキュリティ監視**: ログデータ自体がセキュリティリスクとなる可能性があります。アクセス権限と監査の定期的な見直しを行ってください。

6. **運用モニタリングの自動化**: ログ収集プロセス自体の健全性を監視するメトリクスやアラートを設定し、ログ記録の失敗や遅延を検出できるようにしてください。